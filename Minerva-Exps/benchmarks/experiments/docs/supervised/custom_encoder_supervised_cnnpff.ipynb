{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Training a Custom Encoder on the DAGHAR Dataset\n",
    "\n",
    "\n",
    "In this notebook, we will train a custom encoder from scratch on the DAGHAR KuHAR dataset. The encoder can be **any** `torch.nn.Module` \n",
    "\n",
    "To do this, we will first define your model by:\n",
    "1. Define the encoder. We going to call this encoder as `backbone`.\n",
    "2. Calculating the embedding size of the `backbone`. This is necessary to define the head of the model. This is done by passing a dummy input through the `backbone` and checking the output shape.\n",
    "3. Defining the head of the model. We use a standard MLP classifier as the head, whose input size is the embedding size, followed by a hidden layer of 128 units and an output layer with the number of classes in the dataset, that is, 6.\n",
    "4. Creating a `SimpleSupervisedModel` with the `backbone` and the head. The `SimpleSupervisedModel` is a PyTorch Lightning module that receives the `backbone` and the head as arguments and trains the model end-to-end. This model simply forwards the input through the `backbone`, flattens the output, and passes it through the head to get the logits, whose loss is calculated using the cross-entropy loss.\n",
    "\n",
    "Note that, for sake of reproducibility, you should only change parts related to loading the encoder and defining the head of the model. The rest of the code should remain the same (or at least very similar) to the one provided in this notebook.\n",
    "\n",
    "**Notes:**\n",
    "1. The `backbone` should have a `forward` method that takes a batch of time series as input and returns the output of the encoder (embeddings). Your encoder must accept samples with the shape `(batch_size, channels, steps)`, where `channels` is the number of channels in the time series and `steps` is the number of time steps. For DAGHAR dataset, `channels=6` and `steps=60`. **Thus, your encoder should accept samples with the shape `(batch_size, 6, 60)`.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Dev/minerva/pipelines/base.py:16: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "from minerva.models.nets.base import SimpleSupervisedModel\n",
    "\n",
    "import torchmetrics\n",
    "from minerva.models.nets.time_series.cnns import CNN_PF_Backbone\n",
    "from minerva.data.data_modules.har import MultiModalHARSeriesDataModule\n",
    "from minerva.models.loaders import FromPretrained\n",
    "from minerva.models.nets.base import SimpleSupervisedModel\n",
    "from minerva.models.nets.mlp import MLP\n",
    "from minerva.analysis.metrics.balanced_accuracy import BalancedAccuracy\n",
    "from minerva.analysis.model_analysis import TSNEAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInit signature:\u001b[39m\n",
      "MLP(\n",
      "    layer_sizes: Sequence[int],\n",
      "    activation_cls: type = <\u001b[38;5;28;01mclass\u001b[39;00m \u001b[33m'torch.nn.modules.activation.ReLU'\u001b[39m>,\n",
      "    *args,\n",
      "    **kwargs,\n",
      ")\n",
      "\u001b[31mSource:\u001b[39m        \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m MLP(nn.Sequential):\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    A multilayer perceptron (MLP) implemented as a subclass of nn.Sequential.\u001b[39m\n",
      "\n",
      "\u001b[33m    This MLP is composed of a sequence of linear layers interleaved with ReLU activation\u001b[39m\n",
      "\u001b[33m    functions, except for the final layer which remains purely linear.\u001b[39m\n",
      "\n",
      "\u001b[33m    Example\u001b[39m\n",
      "\u001b[33m    -------\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> mlp = MLP(10, 20, 30, 40)\u001b[39m\n",
      "\u001b[33m    >>> print(mlp)\u001b[39m\n",
      "\u001b[33m    MLP(\u001b[39m\n",
      "\u001b[33m        (0): Linear(in_features=10, out_features=20, bias=True)\u001b[39m\n",
      "\u001b[33m        (1): ReLU()\u001b[39m\n",
      "\u001b[33m        (2): Linear(in_features=20, out_features=30, bias=True)\u001b[39m\n",
      "\u001b[33m        (3): ReLU()\u001b[39m\n",
      "\u001b[33m        (4): Linear(in_features=30, out_features=40, bias=True)\u001b[39m\n",
      "\u001b[33m    )\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __init__(\n",
      "        self,\n",
      "        layer_sizes: Sequence[int],\n",
      "        activation_cls: type = nn.ReLU,\n",
      "        *args,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Initializes the MLP with specified layer sizes.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        layer_sizes : Sequence[int]\u001b[39m\n",
      "\u001b[33m            A sequence of positive integers indicating the size of each layer.\u001b[39m\n",
      "\u001b[33m            At least two integers are required, representing the input and output layers.\u001b[39m\n",
      "\u001b[33m        activation_cls : type\u001b[39m\n",
      "\u001b[33m            The class of the activation function to use between layers. Default is nn.ReLU.\u001b[39m\n",
      "\u001b[33m        *args\u001b[39m\n",
      "\u001b[33m            Additional arguments passed to the activation function.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            Additional keyword arguments passed to the activation function.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        AssertionError\u001b[39m\n",
      "\u001b[33m            If fewer than two layer sizes are provided or if any layer size is not a positive integer.\u001b[39m\n",
      "\u001b[33m        AssertionError\u001b[39m\n",
      "\u001b[33m            If activation_cls does not inherit from torch.nn.Module.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01massert\u001b[39;00m (\n",
      "            len(layer_sizes) >= \u001b[32m2\u001b[39m\n",
      "        ), \u001b[33m\"Multilayer perceptron must have at least 2 layers\"\u001b[39m\n",
      "        \u001b[38;5;28;01massert\u001b[39;00m all(\n",
      "            ls > \u001b[32m0\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m isinstance(ls, int) \u001b[38;5;28;01mfor\u001b[39;00m ls \u001b[38;5;28;01min\u001b[39;00m layer_sizes\n",
      "        ), \u001b[33m\"All layer sizes must be positive integers\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01massert\u001b[39;00m issubclass(\n",
      "            activation_cls, nn.Module\n",
      "        ), \u001b[33m\"activation_cls must inherit from torch.nn.Module\"\u001b[39m\n",
      "\n",
      "        layers = []\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(len(layer_sizes) - \u001b[32m2\u001b[39m):\n",
      "            layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + \u001b[32m1\u001b[39m]))\n",
      "            layers.append(activation_cls(*args, **kwargs))\n",
      "        layers.append(nn.Linear(layer_sizes[-\u001b[32m2\u001b[39m], layer_sizes[-\u001b[32m1\u001b[39m]))\n",
      "\n",
      "        super().__init__(*layers)\n",
      "\u001b[31mFile:\u001b[39m           ~/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Dev/minerva/models/nets/mlp.py\n",
      "\u001b[31mType:\u001b[39m           type\n",
      "\u001b[31mSubclasses:\u001b[39m     "
     ]
    }
   ],
   "source": [
    "MLP??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ID: run_20260205-152539\n",
      "Log dir: ./logs/run_20260205-152539\n"
     ]
    }
   ],
   "source": [
    "# Name of the experiment\n",
    "execution_id = f'run_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "# Directory to save logs\n",
    "log_dir = f\"./logs/{execution_id}\" \n",
    "\n",
    "\n",
    "print(f\"Execution ID: {execution_id}\")\n",
    "print(f\"Log dir: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised training of Custom Encoder\n",
    "\n",
    "In this notebook, we will fine-tune a custom encoder on the DAGHAR dataset. The encoder can be any `torch.nn.Module` that was trained elsewhere and whose checkpoint is available at a `.ckpt` file (saved using `torch.save(model.state_dict())`). This file may contain only the weights from encoder or may contains the weights of the entire model, including the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the Data Module\n",
    "\n",
    "We will use the `MultiModalHARSeriesDataModule` data module to load the DAGHAR dataset for fine-tuning. This data module loads the data in the format required for fine-tuning, which includes sliding window time series data for each sample. Thus, each sample of the dataset will be a 2-element tuple containing the time series (`6x60`, where 6 is the number of features and 60 is the window size) and the corresponding label.\n",
    "\n",
    "The data module requires the following arguments:\n",
    "- `data_path`: Path to the directory containing the dataset (change it to use other dataset from DAGHAR).\n",
    "- `feature_prefix`: The prefix of the columns containing the features. For each prefix, we will create a different channel with all columns that start with the prefix.\n",
    "- `label`: The name of the column containing the labels.\n",
    "- `features_as_channels`: If True, for each prefix, we will create a different channel with all columns that start with the prefix. If False, we will concatenate all columns with the same prefix into a single channel (the sample will be a tensor of 1x360 instead of 6x60).\n",
    "- `cast_to`: The data type to cast the features (float32).\n",
    "- `batch_size`: The batch size for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figures\t\t\t Minerva-Dev   minerva_ssl_env\tsetup_dev_container.py\n",
      "install_requirements.sh  Minerva-Exps  README.md\tshared_data\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalHARSeriesDataModule(data_path=../../../../../shared_data/daghar/standardized_view/KuHar, batch_size=64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = MultiModalHARSeriesDataModule(\n",
    "    data_path=\"../../../../../shared_data/daghar/standardized_view/KuHar/\",\n",
    "    feature_prefixes=[\"accel-x\", \"accel-y\", \"accel-z\", \"gyro-x\", \"gyro-y\", \"gyro-z\"],\n",
    "    label=\"standard activity code\",\n",
    "    features_as_channels=True,\n",
    "    cast_to=\"float32\",\n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the Supervised Model\n",
    "\n",
    "We first going to create the `backbone` of our model, that is our encoder. To do this, we:\n",
    "1. Copy-and-paste the code of the encoder in the cell below. Should be a `torch.nn.Module` or equivalent. You should copy all code necessary to define the encoder, including imports, class definition, the `forward` method, and any other methods or classes that are necessary to define the encoder.\n",
    "\n",
    "**NOTE**: \n",
    "1. Your encoder **must accept samples with the shape `(batch_size, 6, 60)`**. This is the shape of the samples in the DAGHAR dataset. If your encoder does not accept samples with this shape, you should modify it to accept samples with this shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Definition*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from minerva.models.nets.tnc import RnnEncoder,TSEncoder\n",
    "from minerva.models.nets.mlp import MLP\n",
    "from minerva.models.nets.base import SimpleSupervisedModel\n",
    "from minerva.models.nets.time_series.resnet import _ResNet1D, ResNetSEBlock\n",
    "from minerva.models.nets.time_series.cnns import CNN_PF_Backbone\n",
    "from minerva.models.nets.time_series.imu_transformer import _IMUTransformerEncoder\n",
    "from minerva.models.nets.lfr_har_architectures import HARSCnnEncoder\n",
    "\n",
    "backbone = CNN_PF_Backbone(include_middle=True) #768\n",
    "\n",
    "# backbone = HARSCnnEncoder(dim=2304,input_channel= 6,inner_conv_output_dim= 1280) #2304\n",
    "\n",
    "# backbone = _ResNet1D(input_shape= (6, 60),residual_block_cls=ResNetSEBlock) #64\n",
    "\n",
    "# backbone = RnnEncoder(\n",
    "#         hidden_size=100,\n",
    "#         in_channel=6,\n",
    "#         encoding_size=320,\n",
    "#         bidirectional=True,\n",
    "#         num_layers=1,\n",
    "#         dropout=0,\n",
    "#         cell_type='GRU'\n",
    "#         # device='cuda',\n",
    "#         permute=True\n",
    "#     ) #320\n",
    "\n",
    "# backbone = TSEncoder(input_dims=6, output_dims=320, hidden_dims=64, depth=10,permute=True) #320\n",
    "\n",
    "# backbone = _IMUTransformerEncoder(\n",
    "#         input_shape= (6, 60),\n",
    "#         transformer_dim = 64,\n",
    "#         encode_position = True,\n",
    "#         nhead= 8,\n",
    "#         dim_feedforward = 128,\n",
    "#         transformer_dropout = 0.1,\n",
    "#         transformer_activation = \"gelu\",\n",
    "#         num_encoder_layers = 6,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the head\n",
    "\n",
    "We will define the head of the model. The head is a simple MLP classifier that receives the embeddings from the encoder and outputs the logits. The head consists of a single hidden layer with 128 units and an output layer with the number of classes in the dataset, that is, 6.\n",
    "In order to know the input size of the head, we need to calculate the embedding size of the encoder. This is done by passing a dummy input through the encoder and checking the output shape. Let's pick the first batch of the training data and pass it through the encoder to get the embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=True\n",
      "O primeiro batch de treino tem shape X=(64, 6, 60) e y=(64,)\n"
     ]
    }
   ],
   "source": [
    "# Pega os dataloader de treino\n",
    "data_module.setup(\"fit\")\n",
    "train_data_loader = data_module.train_dataloader()\n",
    "\n",
    "# Obtem o primeiro batch de treino (64 amostras de 6x60)\n",
    "first_batch = next(iter(train_data_loader))\n",
    "\n",
    "X, y = first_batch\n",
    "print(f\"O primeiro batch de treino tem shape X={tuple(X.shape)} e y={tuple(y.shape)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a single forward pass through the encoder with the first batch of the training data and checked the output shape that is `(64, 16, 60)`. The embedding size is `16 x 30 = 480`, that is, the product of the number of channels and the number of steps in the output of the encoder. Thus, the input layer of our MLP head will have 480 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O embedding tem shape (64, 64, 12)\n",
      "O embedding final, achatado, tem o shape de 64\n"
     ]
    }
   ],
   "source": [
    "embeddings = backbone(X)\n",
    "# multiplica produtorio de todas as camadas com exceÃ§Ã£o da de batches\n",
    "mlp_input_shape = embeddings.shape[1] #* embeddings.shape[2]\n",
    "print(f\"O embedding tem shape {tuple(embeddings.shape)}\")\n",
    "print(f\"O embedding final, achatado, tem o shape de {mlp_input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the head of the model in the cell below. The head will be a simple MLP classifier with:\n",
    "- A input layer with 480 units (`mlp_input_shape` variable).\n",
    "- A hidden layer with 128 units.\n",
    "- An output layer with 6 units, that is the number of classes in the dataset (`num_classes` variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 6\n",
    "head = MLP([768, 128, num_classes])\n",
    "head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the SimpleSupervisedModel\n",
    "\n",
    "Finally, we use the `SimpleSupervisedModel` class to create the supervised model with the encoder as the backbone and the MLP classifier as the head. The `SimpleSupervisedModel` class requires the following arguments:\n",
    "- `backbone`: The backbone model (`FromPretrained` model).\n",
    "- `fc`: The head model (the MLP classifier).\n",
    "- `loss_fn`: The loss function to use for training (`CrossEntropyLoss`).\n",
    "- `flatten`: Whether to flatten the input before passing it through the head. Usually, the input is flattened if the backbone outputs a tensor with more than two dimensions.\n",
    "- `train_metrics`: A dictionary where the keys are the names of the metrics and the values are the functions that calculate the metrics. The metrics function should use `torchmetrics` API to calculate the metrics.\n",
    "- `val_metrics`: A dictionary where the keys are the names of the metrics and the values are the functions that calculate the metrics. The metrics function should use `torchmetrics` API to calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleSupervisedModel(\n",
       "  (backbone): CNN_PF_Backbone(\n",
       "    (first_padder): ZeroPadder2D(pad_at=(3,), padding_size=2)\n",
       "    (upper_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (lower_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (middle_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (shared_part): Sequential(\n",
       "      (0): Conv2d(48, 64, kernel_size=(3, 5), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): MLP(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleSupervisedModel(\n",
    "    backbone=backbone,\n",
    "    fc=head,\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    flatten=True,\n",
    "    train_metrics={\n",
    "        \"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6),\n",
    "    },\n",
    "    val_metrics={\n",
    "        \"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6),\n",
    "    },\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 145,830\n",
      "Trainable model parameters: 145,830\n",
      "\n",
      "Backbone:\n",
      "  Total parameters: 46,624\n",
      "  Trainable parameters: 46,624\n",
      "\n",
      "Classification Head:\n",
      "  Total parameters: 99,206\n",
      "  Trainable parameters: 99,206\n",
      "\n",
      "Verification:\n",
      "Backbone + Head total: 145,830\n",
      "Should match total: 145,830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "MACs: 1,673,856,000.0\n",
      "Parameters: 145,830.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Measure ALL model parameters (including backbone AND head)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total model parameters: {total_params:,}\")\n",
    "print(f\"Trainable model parameters: {trainable_params:,}\")\n",
    "\n",
    "# Option 2: Measure components separately (as you intended)\n",
    "# Backbone parameters\n",
    "backbone_total = sum(p.numel() for p in model.backbone.parameters())\n",
    "backbone_trainable = sum(p.numel() for p in model.backbone.parameters() if p.requires_grad)\n",
    "\n",
    "# Head parameters (use model.fc, not head variable)\n",
    "head_total = sum(p.numel() for p in model.fc.parameters())\n",
    "head_trainable = sum(p.numel() for p in model.fc.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nBackbone:\")\n",
    "print(f\"  Total parameters: {backbone_total:,}\")\n",
    "print(f\"  Trainable parameters: {backbone_trainable:,}\")\n",
    "\n",
    "print(f\"\\nClassification Head:\")\n",
    "print(f\"  Total parameters: {head_total:,}\")\n",
    "print(f\"  Trainable parameters: {head_trainable:,}\")\n",
    "\n",
    "# Verify the sum matches Option 1\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Backbone + Head total: {backbone_total + head_total:,}\")\n",
    "print(f\"Should match total: {total_params:,}\")\n",
    "\n",
    "from thop import profile\n",
    "evaluation_data = torch.rand(1000, 6, 60, device='cuda')\n",
    "model.to('cuda')\n",
    "macs, params = profile(model, inputs=(evaluation_data,))\n",
    "\n",
    "print(f\"MACs: {macs:,}\")\n",
    "print(f\"Parameters: {params:,}\")\n",
    "\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the Pytorch Lightning Trainer Configuration\n",
    "\n",
    "We will define the PyTorch Lightning Trainer configuration for fine-tuning the model.\n",
    "\n",
    "The trainer configuration includes the following parameters:\n",
    "- `max_epochs`: The maximum number of epochs to train the model.\n",
    "- `accelerator`: The accelerator to use for training: `cpu`, `gpu`, or `tpu`.\n",
    "- `devices`: The number of accelerators to use for training.\n",
    "- `logger`: The logger to use for logging the training progress.\n",
    "- `limit_*_batches`: The number of batches to use for training and validation. **This is useful for debugging and testing the model.**. You should remove these parameters when training the model for real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/site-packages/lightning/pytorch/trainer/setup.py:175: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "ğŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x7164c21b8790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "## Logger\n",
    "logger = CSVLogger(save_dir=log_dir, name='cpc-finetune', version=execution_id)\n",
    "\n",
    "## Trainer\n",
    "trainer = L.Trainer(\n",
    "    # Maximum number of epochs to train\n",
    "    max_epochs=20,\n",
    "    # Training on GPU\n",
    "    accelerator=\"cpu\",\n",
    "    # We will train using 1 gpu\n",
    "    devices=1,\n",
    "    # Logger for logging\n",
    "    logger=logger,\n",
    "    # List of callbacks\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # Only for testing. Remove for production. We will only train using 1 batch of training and validation\n",
    "    # limit_train_batches=1,\n",
    "    # limit_val_batches=1,\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the fine-tuning pipeline (and running the training)\n",
    "\n",
    "We will create a `SimpleLightningPipeline` to fine-tune the model. This pipeline receives the following arguments:\n",
    "- `model`: The model to train.\n",
    "- `trainer`: The PyTorch Lightning Trainer to use for training.\n",
    "- `log_dir`: The directory to save the logs, checkpoints, and other artifacts of the training process.\n",
    "- `save_run_status`: If True, save the status of the run to the log directory. This is useful for reprodutibility purposes.\n",
    "- `seed`: The seed to use for random number generators in PyTorch, NumPy, and other libraries.\n",
    "\n",
    "This pipeline is optional, as user can simply use `trainer.fit(model, datamodule)` directly to train the model. However, the pipeline provides a more organized way to train the model and save required information for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the pipeline to fine-tune the model on the DAGHAR dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Seed set to: 42 **\n",
      "Pipeline info saved at: /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/run_2026-02-05-15-25-40ff081ec5.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name     </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>â”‚ backbone â”‚ CNN_PF_Backbone  â”‚ 46.6 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>â”‚ fc       â”‚ MLP              â”‚ 99.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>â”‚ loss_fn  â”‚ CrossEntropyLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName    \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0mâ”‚ backbone â”‚ CNN_PF_Backbone  â”‚ 46.6 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0mâ”‚ fc       â”‚ MLP              â”‚ 99.2 K â”‚ train â”‚     0 â”‚\n",
       "â”‚\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0mâ”‚ loss_fn  â”‚ CrossEntropyLoss â”‚      0 â”‚ train â”‚     0 â”‚\n",
       "â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 145 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 145 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 23                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 145 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 145 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 23                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using DataLoader with shuffle=False\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using DataLoader with shuffle=False\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use \n",
       "`isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use \n",
       "`isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many \n",
       "workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` \n",
       "in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'val_dataloader' does not have many \n",
       "workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` \n",
       "in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using DataLoader with shuffle=True\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Using DataLoader with shuffle=True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many \n",
       "workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` \n",
       "in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'train_dataloader' does not have many \n",
       "workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` \n",
       "in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/loops/fit_loop.py:317: The number of training batches (21) is smaller than the logging\n",
       "interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the \n",
       "training epoch.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/lightning/pytorch/loops/fit_loop.py:317: The number of training batches (21) is smaller than the logging\n",
       "interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the \n",
       "training epoch.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ fit took 13.63s â†’ saved to /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/timings_fit.csv\n",
      "Pipeline info saved at: /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/run_2026-02-05-15-25-40ff081ec5.yaml\n"
     ]
    }
   ],
   "source": [
    "train_pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Fine-tuned Model\n",
    "\n",
    "After fine-tuning the encoder on the DAGHAR dataset, we will evaluate the model's performance on the test set of the same dataset. We create a simple evaluation pipeline, that will:\n",
    "1. Run forward on test set.\n",
    "2. Calculcate the metrics. This is specified in the `classification_metrics` dictionary, where the keys are the names of the metrics and the values are the functions that calculate the metrics. The metrics function should use `torchmetrics` API to calculate the metrics.\n",
    "3. Perform model analysis, such as plot t-sne embeddings.\n",
    "\n",
    "The test pipeline requires the following arguments:\n",
    "- `model`: The fine-tuned model to evaluate.\n",
    "- `trainer`: The PyTorch Lightning Trainer configuration.\n",
    "- `log_dir`: The directory to save the evaluation logs.\n",
    "- `seed`: The random seed for reproducibility.\n",
    "- `classification_metrics`: A dictionary where the keys are the names of the metrics and the values are the functions that calculate the metrics. The metrics function should use `torchmetrics` API to calculate the metrics.\n",
    "- `model_analysis`: A function that performs model analysis, such as plotting t-sne embeddings.\n",
    "\n",
    "Finally, we run the evaluation pipeline with the test data module to evaluate the model on the test set. We set the `task` parameter of the `run` method to `evaluate` to evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42,\n",
    "    classification_metrics={\n",
    "        \"accuracy\": torchmetrics.Accuracy(num_classes=6, task=\"multiclass\"),\n",
    "        \"f1\": torchmetrics.F1Score(num_classes=6, task=\"multiclass\"),\n",
    "        \"precision\": torchmetrics.Precision(num_classes=6, task=\"multiclass\"),\n",
    "        \"recall\": torchmetrics.Recall(num_classes=6, task=\"multiclass\"),\n",
    "        # \"balanced_accuracy\": BalancedAccuracy(num_classes=6, task=\"multiclass\",adjusted=False), # not used anymore\n",
    "        \"balanced_accuracy\": torchmetrics.Accuracy(num_classes=6, task=\"multiclass\"),\n",
    "    },\n",
    "    apply_metrics_per_sample=False,\n",
    "    model_analysis={\n",
    "        \"tsne\": TSNEAnalysis(\n",
    "        text_size=28,\n",
    "        label_names={\n",
    "            0: \"sit\",\n",
    "            1: \"stand\",\n",
    "            2: \"walk\",\n",
    "            3: \"stair up\",\n",
    "            4: \"stair down\",\n",
    "            5: \"run\",\n",
    "            6: \"stair up and down\",\n",
    "        },\n",
    "        marker_symbols={\n",
    "            \"sit\": \"x-open\",\n",
    "            \"stand\": \"cross-open\",\n",
    "            \"stair up\": \"triangle-up-open\",\n",
    "            \"stair down\": \"triangle-down-open\",\n",
    "            \"walk\": \"circle-open\",\n",
    "            \"run\": \"star-open\",\n",
    "        },\n",
    "        colors={\n",
    "            \"sit\": \"#1f77b4\",\n",
    "            \"stand\": \"#ff7f0e\",\n",
    "            \"walk\": \"#2ca02c\",\n",
    "            \"stair up\": \"#9467bd\",\n",
    "            \"stair down\": \"#d62728\",\n",
    "            \"run\": \"#8c564b\",\n",
    "        },\n",
    "        height=1000,\n",
    "        width=1000,\n",
    "        legend_title=\"Activity\",\n",
    "        title=\" \",\n",
    "        output_filename=\"tnse_analysis.png\",\n",
    "        x_axis_title=\"1st Component\",\n",
    "        y_axis_title=\"2nd Component\",\n",
    "    )\n",
    "}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/checkpoints/epoch=0-step=21-v2.ckpt\n",
      "Loaded model weights from the checkpoint at /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/checkpoints/epoch=0-step=21-v2.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Seed set to: 42 **\n",
      "Pipeline info saved at: /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/run_2026-02-05-15-25-549208cccf.yaml\n",
      "Using DataLoader with shuffle=False\n",
      "ğŸ” True labels shape: torch.Size([144])\n",
      "ğŸ” Unique true classes: tensor([0, 1, 2, 3, 4, 5])\n",
      "ğŸ” True class distribution: tensor([24, 24, 24, 24, 24, 24])\n",
      "Using DataLoader with shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/site-packages/lightning/pytorch/utilities/_pytree.py:21: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:434: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/minerva_ssl_env/lib/python3.11/sit\n",
       "e-packages/rich/live.py:260: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " saving y and yhat \n",
      "\n",
      "\n",
      "ğŸ” Raw predictions shape: torch.Size([144, 6])\n",
      "Running classification metrics...\n",
      "\n",
      "ğŸ“Š Misclassification summary\n",
      "Total: 67/144 (46.5278%)\n",
      "Class 0: 0/24 (0.00%)\n",
      "Class 1: 24/24 (100.00%)\n",
      "Class 2: 22/24 (91.67%)\n",
      "Class 3: 0/24 (0.00%)\n",
      "Class 4: 21/24 (87.50%)\n",
      "Class 5: 0/24 (0.00%)\n",
      "ğŸ” Predicted classes shape: torch.Size([144])\n",
      "ğŸ” Unique predicted classes: tensor([0, 2, 3, 4, 5])\n",
      "ğŸ” Predicted class distribution: tensor([48,  0,  2, 47,  3, 44])\n",
      "Metric accuracy: [0.5347222089767456]\n",
      "Metric f1: [0.5347222089767456]\n",
      "Metric precision: [0.5347222089767456]\n",
      "Metric recall: [0.5347222089767456]\n",
      "Metric balanced_accuracy: [0.5347222089767456]\n",
      "ğŸ” Manual accuracy: 0.5347 (77/144)\n",
      "BalancedAccuracy()\n",
      "\n",
      "\n",
      "ğŸ” Balanced Accuracy: 0.5347\n",
      "\n",
      "\n",
      "Running model analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Dev/minerva/analysis/model_analysis.py:196: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
      "  X = torch.tensor(X, device=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=False\n",
      "t-SNE PNG saved to /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/tnse_analysis.png\n",
      "t-SNE HTML saved to /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/tnse_analysis.html\n",
      "Metrics saved to /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/metrics_2026-02-05-15-25-549208cccf.yaml\n",
      "â±ï¸ evaluate took 2.27s â†’ saved to /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/timings_evaluate.csv\n",
      "Pipeline info saved at: /home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/run_2026-02-05-15-25-549208cccf.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classification': {'accuracy': [0.5347222089767456],\n",
       "  'f1': [0.5347222089767456],\n",
       "  'precision': [0.5347222089767456],\n",
       "  'recall': [0.5347222089767456],\n",
       "  'balanced_accuracy': [0.5347222089767456]},\n",
       " 'analysis': {'tsne': {'png_path': '/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/tnse_analysis.png',\n",
       "   'html_path': '/home/gustavo-luz/code/hiaac/paper_access_private_git/Benchmarking_Enconders_SSL/Minerva-Exps/benchmarks/experiments/docs/supervised/logs/run_20260205-152539/tnse_analysis.html'}},\n",
       " 'misclassification': {'total': {'samples': 144,\n",
       "   'misclassified': 67,\n",
       "   'rate': 0.4652777777777778},\n",
       "  'per_class': {0: {'total': 24,\n",
       "    'misclassified': 0,\n",
       "    'misclassification_rate': 0.0},\n",
       "   1: {'total': 24, 'misclassified': 24, 'misclassification_rate': 1.0},\n",
       "   2: {'total': 24,\n",
       "    'misclassified': 22,\n",
       "    'misclassification_rate': 0.9166666666666666},\n",
       "   3: {'total': 24, 'misclassified': 0, 'misclassification_rate': 0.0},\n",
       "   4: {'total': 24, 'misclassified': 21, 'misclassification_rate': 0.875},\n",
       "   5: {'total': 24, 'misclassified': 0, 'misclassification_rate': 0.0}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline.run(\n",
    "    data_module, task=\"evaluate\", ckpt_path=checkpoint_callback.best_model_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
