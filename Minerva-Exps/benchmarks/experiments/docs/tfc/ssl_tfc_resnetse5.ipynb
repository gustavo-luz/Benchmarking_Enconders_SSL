{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Frequency Consistency (TFC) + CNN PFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import lightning as L\n",
    "import torch\n",
    "import torchmetrics\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from minerva.analysis.metrics.balanced_accuracy import BalancedAccuracy\n",
    "from minerva.analysis.model_analysis import TSNEAnalysis\n",
    "from minerva.data.data_modules.har import MultiModalHARSeriesDataModule\n",
    "from minerva.data.data_modules.har_rodrigues_24 import HARDataModuleCPC\n",
    "from minerva.models.loaders import FromPretrained\n",
    "from minerva.models.nets.time_series.resnet import _ResNet1D, ResNetSEBlock\n",
    "from minerva.models.ssl.tfc import TFC_Model, TFC_Backbone\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ID: run_20260127-022244\n",
      "Log dir: ./logs/run_20260127-022244\n"
     ]
    }
   ],
   "source": [
    "execution_id = f'run_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "log_dir = f\"./logs/{execution_id}\" \n",
    "\n",
    "print(f\"Execution ID: {execution_id}\")\n",
    "print(f\"Log dir: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training with TFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HARDataModuleCPC(batch_size=64, datasets=/workspaces/HIAAC-KR-Dev-Container/shared_data/rodrigues_2024_datasets/1-1/wisdm)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = HARDataModuleCPC(\n",
    "    data_path=\"/workspaces/HIAAC-KR-Dev-Container/shared_data/rodrigues_2024_datasets/1-1/wisdm\",\n",
    "    input_size=6,\n",
    "    window=60,\n",
    "    overlap=60,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the TF-C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a batch of data\n",
    "from minerva.models.nets.tnc import TSEncoder\n",
    "data_module.setup(\"fit\")\n",
    "dataset = data_module.train_dataloader()\n",
    "batch_x, batch_y = next(iter(dataset))\n",
    "from minerva.models.nets.time_series.resnet import _ResNet1D\n",
    "# Create the model and forward the batch to check the output shape\n",
    "g_enc = _ResNet1D(input_shape=(6,60))\n",
    "r = g_enc.forward(batch_x)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W127 02:22:48.041283031 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.042423279 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.042747847 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.043681581 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.043981397 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.044620803 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.044913341 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.045550900 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.045839695 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.046475521 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.046762789 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.049417799 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.049821494 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.050125915 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.050774612 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.051075939 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.051694906 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.051982083 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.052608657 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.052891783 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.053513609 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:48.053793294 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFC_Model(\n",
       "  (backbone): TFC_Backbone(\n",
       "    (time_encoder): _ResNet1D(\n",
       "      (conv_block): ConvolutionalBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv1d(6, 64, kernel_size=(5,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (residual_blocks): Sequential(\n",
       "        (0): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (frequency_encoder): _ResNet1D(\n",
       "      (conv_block): ConvolutionalBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv1d(6, 64, kernel_size=(5,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (residual_blocks): Sequential(\n",
       "        (0): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (time_projector): TFC_Standard_Projector(\n",
       "      (projector): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): IgnoreWhenBatch1(\n",
       "          (module): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (frequency_projector): TFC_Standard_Projector(\n",
       "      (projector): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): IgnoreWhenBatch1(\n",
       "          (module): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): NTXentLoss_poly(\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (_cosine_similarity): CosineSimilarity()\n",
       "    (criterion): CrossEntropyLoss()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = TFC_Backbone(\n",
    "    input_channels=6,\n",
    "    TS_length=60,\n",
    "    single_encoding_size=128,\n",
    "    time_encoder=_ResNet1D(input_shape=(6,60),residual_block_cls=ResNetSEBlock),\n",
    "    frequency_encoder=_ResNet1D(input_shape=(6,60),residual_block_cls=ResNetSEBlock),\n",
    ")\n",
    "model = TFC_Model(\n",
    "    input_channels=6,\n",
    "    batch_size=64,\n",
    "    # TS_length=r.shape[-1],\n",
    "    TS_length=60,\n",
    "    num_classes=6,\n",
    "    single_encoding_size=128,\n",
    "    backbone=backbone,\n",
    "    pred_head=None,\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the Pytorch Lightning Trainer Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x70b367aee980>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "## Logger\n",
    "logger = CSVLogger(save_dir=log_dir, name='tfc-cnn-pff-pretraining', version=execution_id)\n",
    "\n",
    "## Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # Only for testing. Remove for production. We will only train using 1 batch\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the training pipeline (and running the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/codecarbon/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | backbone | TFC_Backbone    | 353 K  | train\n",
      "1 | loss_fn  | NTXentLoss_poly | 0      | train\n",
      "-----------------------------------------------------\n",
      "353 K     Trainable params\n",
      "0         Non-trainable params\n",
      "353 K     Total params\n",
      "1.416     Total estimated model params size (MB)\n",
      "167       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Seed set to: 42 **\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/codecarbon/logs/run_20260127-022244/run_2026-01-27-02-22-4978f15850.yaml\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:01<00:00,  0.92it/s, v_num=2244, val_loss=3.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:01<00:00,  0.70it/s, v_num=2244, val_loss=3.600]\n",
      "⏱️ fit took 5.59s → saved to /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/codecarbon/logs/run_20260127-022244/timings_fit.csv\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/codecarbon/logs/run_20260127-022244/run_2026-01-27-02-22-4978f15850.yaml\n"
     ]
    }
   ],
   "source": [
    "train_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42\n",
    ")\n",
    "train_pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inspecting checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backbone.time_encoder.conv_block.block.0.weight',\n",
       " 'backbone.time_encoder.conv_block.block.0.bias',\n",
       " 'backbone.time_encoder.conv_block.block.1.weight',\n",
       " 'backbone.time_encoder.conv_block.block.1.bias',\n",
       " 'backbone.time_encoder.conv_block.block.1.running_mean',\n",
       " 'backbone.time_encoder.conv_block.block.1.running_var',\n",
       " 'backbone.time_encoder.conv_block.block.1.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.1.weight',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.1.bias',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.1.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.1.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.1.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.3.weight',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.3.bias',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.4.weight',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.4.bias',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.4.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.4.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.4.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.5.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.5.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.5.block.2.weight',\n",
       " 'backbone.time_encoder.residual_blocks.0.block.5.block.2.bias',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.1.weight',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.1.bias',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.1.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.1.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.1.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.3.weight',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.3.bias',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.4.weight',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.4.bias',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.4.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.4.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.4.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.5.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.5.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.5.block.2.weight',\n",
       " 'backbone.time_encoder.residual_blocks.1.block.5.block.2.bias',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.1.weight',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.1.bias',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.1.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.1.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.1.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.3.weight',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.3.bias',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.4.weight',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.4.bias',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.4.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.4.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.4.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.5.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.5.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.5.block.2.weight',\n",
       " 'backbone.time_encoder.residual_blocks.2.block.5.block.2.bias',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.1.weight',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.1.bias',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.1.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.1.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.1.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.3.weight',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.3.bias',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.4.weight',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.4.bias',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.4.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.4.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.4.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.5.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.5.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.5.block.2.weight',\n",
       " 'backbone.time_encoder.residual_blocks.3.block.5.block.2.bias',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.1.weight',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.1.bias',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.1.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.1.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.1.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.3.weight',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.3.bias',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.4.weight',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.4.bias',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.4.running_mean',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.4.running_var',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.4.num_batches_tracked',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.5.block.0.weight',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.5.block.0.bias',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.5.block.2.weight',\n",
       " 'backbone.time_encoder.residual_blocks.4.block.5.block.2.bias',\n",
       " 'backbone.frequency_encoder.conv_block.block.0.weight',\n",
       " 'backbone.frequency_encoder.conv_block.block.0.bias',\n",
       " 'backbone.frequency_encoder.conv_block.block.1.weight',\n",
       " 'backbone.frequency_encoder.conv_block.block.1.bias',\n",
       " 'backbone.frequency_encoder.conv_block.block.1.running_mean',\n",
       " 'backbone.frequency_encoder.conv_block.block.1.running_var',\n",
       " 'backbone.frequency_encoder.conv_block.block.1.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.1.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.1.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.1.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.1.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.1.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.3.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.3.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.4.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.4.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.4.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.4.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.4.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.5.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.5.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.5.block.2.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.0.block.5.block.2.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.1.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.1.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.1.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.1.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.1.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.3.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.3.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.4.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.4.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.4.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.4.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.4.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.5.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.5.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.5.block.2.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.1.block.5.block.2.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.1.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.1.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.1.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.1.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.1.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.3.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.3.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.4.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.4.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.4.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.4.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.4.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.5.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.5.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.5.block.2.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.2.block.5.block.2.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.1.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.1.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.1.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.1.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.1.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.3.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.3.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.4.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.4.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.4.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.4.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.4.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.5.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.5.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.5.block.2.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.3.block.5.block.2.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.1.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.1.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.1.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.1.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.1.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.3.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.3.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.4.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.4.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.4.running_mean',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.4.running_var',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.4.num_batches_tracked',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.5.block.0.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.5.block.0.bias',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.5.block.2.weight',\n",
       " 'backbone.frequency_encoder.residual_blocks.4.block.5.block.2.bias',\n",
       " 'backbone.time_projector.projector.0.weight',\n",
       " 'backbone.time_projector.projector.0.bias',\n",
       " 'backbone.time_projector.projector.1.module.weight',\n",
       " 'backbone.time_projector.projector.1.module.bias',\n",
       " 'backbone.time_projector.projector.1.module.running_mean',\n",
       " 'backbone.time_projector.projector.1.module.running_var',\n",
       " 'backbone.time_projector.projector.1.module.num_batches_tracked',\n",
       " 'backbone.time_projector.projector.3.weight',\n",
       " 'backbone.time_projector.projector.3.bias',\n",
       " 'backbone.frequency_projector.projector.0.weight',\n",
       " 'backbone.frequency_projector.projector.0.bias',\n",
       " 'backbone.frequency_projector.projector.1.module.weight',\n",
       " 'backbone.frequency_projector.projector.1.module.bias',\n",
       " 'backbone.frequency_projector.projector.1.module.running_mean',\n",
       " 'backbone.frequency_projector.projector.1.module.running_var',\n",
       " 'backbone.frequency_projector.projector.1.module.num_batches_tracked',\n",
       " 'backbone.frequency_projector.projector.3.weight',\n",
       " 'backbone.frequency_projector.projector.3.bias']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = checkpoint_callback.last_model_path\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cuda\")\n",
    "ckpt = ckpt.get(\"state_dict\", ckpt)\n",
    "list(ckpt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning with Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalHARSeriesDataModule(data_path=/workspaces/HIAAC-KR-Dev-Container/shared_data/daghar/standardized_view/MotionSense, batch_size=64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = MultiModalHARSeriesDataModule(\n",
    "    data_path=\"/workspaces/HIAAC-KR-Dev-Container/shared_data/daghar/standardized_view/MotionSense/\",\n",
    "    feature_prefixes=[\"accel-x\", \"accel-y\", \"accel-z\", \"gyro-x\", \"gyro-y\", \"gyro-z\"],\n",
    "    label=\"standard activity code\",\n",
    "    features_as_channels=True,\n",
    "    cast_to=\"float32\",\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=True\n",
      "Using DataLoader with shuffle=False\n",
      "torch.Size([64, 6, 60]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Pega os dataloaders de treino e validação\n",
    "data_module.setup(\"fit\")\n",
    "train_data_loader = data_module.train_dataloader()\n",
    "validation_data_loader = data_module.val_dataloader()\n",
    "first_batch = next(iter(train_data_loader))\n",
    "\n",
    "X, y = first_batch\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the CNN PFF Model for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W127 02:22:57.147186300 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.148156047 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.148396818 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.149063704 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.149284309 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.149805327 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.150129420 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.150643347 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.150997542 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.151563652 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.151769538 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.153849854 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.154224786 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.154446045 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.154964231 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.155227008 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.155736679 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.156085378 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.156574887 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.156889971 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.157391595 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W127 02:22:57.157596793 NNPACK.cpp:57] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing key renaming with: {'backbone.': ''}\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.0.weight -> time_encoder.conv_block.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.0.bias -> time_encoder.conv_block.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.1.weight -> time_encoder.conv_block.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.1.bias -> time_encoder.conv_block.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.1.running_mean -> time_encoder.conv_block.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.1.running_var -> time_encoder.conv_block.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.conv_block.block.1.num_batches_tracked -> time_encoder.conv_block.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.0.weight -> time_encoder.residual_blocks.0.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.0.bias -> time_encoder.residual_blocks.0.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.1.weight -> time_encoder.residual_blocks.0.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.1.bias -> time_encoder.residual_blocks.0.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.1.running_mean -> time_encoder.residual_blocks.0.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.1.running_var -> time_encoder.residual_blocks.0.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.1.num_batches_tracked -> time_encoder.residual_blocks.0.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.3.weight -> time_encoder.residual_blocks.0.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.3.bias -> time_encoder.residual_blocks.0.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.4.weight -> time_encoder.residual_blocks.0.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.4.bias -> time_encoder.residual_blocks.0.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.4.running_mean -> time_encoder.residual_blocks.0.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.4.running_var -> time_encoder.residual_blocks.0.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.4.num_batches_tracked -> time_encoder.residual_blocks.0.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.5.block.0.weight -> time_encoder.residual_blocks.0.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.5.block.0.bias -> time_encoder.residual_blocks.0.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.5.block.2.weight -> time_encoder.residual_blocks.0.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.0.block.5.block.2.bias -> time_encoder.residual_blocks.0.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.0.weight -> time_encoder.residual_blocks.1.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.0.bias -> time_encoder.residual_blocks.1.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.1.weight -> time_encoder.residual_blocks.1.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.1.bias -> time_encoder.residual_blocks.1.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.1.running_mean -> time_encoder.residual_blocks.1.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.1.running_var -> time_encoder.residual_blocks.1.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.1.num_batches_tracked -> time_encoder.residual_blocks.1.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.3.weight -> time_encoder.residual_blocks.1.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.3.bias -> time_encoder.residual_blocks.1.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.4.weight -> time_encoder.residual_blocks.1.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.4.bias -> time_encoder.residual_blocks.1.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.4.running_mean -> time_encoder.residual_blocks.1.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.4.running_var -> time_encoder.residual_blocks.1.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.4.num_batches_tracked -> time_encoder.residual_blocks.1.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.5.block.0.weight -> time_encoder.residual_blocks.1.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.5.block.0.bias -> time_encoder.residual_blocks.1.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.5.block.2.weight -> time_encoder.residual_blocks.1.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.1.block.5.block.2.bias -> time_encoder.residual_blocks.1.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.0.weight -> time_encoder.residual_blocks.2.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.0.bias -> time_encoder.residual_blocks.2.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.1.weight -> time_encoder.residual_blocks.2.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.1.bias -> time_encoder.residual_blocks.2.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.1.running_mean -> time_encoder.residual_blocks.2.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.1.running_var -> time_encoder.residual_blocks.2.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.1.num_batches_tracked -> time_encoder.residual_blocks.2.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.3.weight -> time_encoder.residual_blocks.2.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.3.bias -> time_encoder.residual_blocks.2.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.4.weight -> time_encoder.residual_blocks.2.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.4.bias -> time_encoder.residual_blocks.2.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.4.running_mean -> time_encoder.residual_blocks.2.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.4.running_var -> time_encoder.residual_blocks.2.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.4.num_batches_tracked -> time_encoder.residual_blocks.2.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.5.block.0.weight -> time_encoder.residual_blocks.2.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.5.block.0.bias -> time_encoder.residual_blocks.2.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.5.block.2.weight -> time_encoder.residual_blocks.2.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.2.block.5.block.2.bias -> time_encoder.residual_blocks.2.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.0.weight -> time_encoder.residual_blocks.3.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.0.bias -> time_encoder.residual_blocks.3.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.1.weight -> time_encoder.residual_blocks.3.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.1.bias -> time_encoder.residual_blocks.3.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.1.running_mean -> time_encoder.residual_blocks.3.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.1.running_var -> time_encoder.residual_blocks.3.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.1.num_batches_tracked -> time_encoder.residual_blocks.3.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.3.weight -> time_encoder.residual_blocks.3.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.3.bias -> time_encoder.residual_blocks.3.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.4.weight -> time_encoder.residual_blocks.3.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.4.bias -> time_encoder.residual_blocks.3.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.4.running_mean -> time_encoder.residual_blocks.3.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.4.running_var -> time_encoder.residual_blocks.3.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.4.num_batches_tracked -> time_encoder.residual_blocks.3.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.5.block.0.weight -> time_encoder.residual_blocks.3.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.5.block.0.bias -> time_encoder.residual_blocks.3.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.5.block.2.weight -> time_encoder.residual_blocks.3.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.3.block.5.block.2.bias -> time_encoder.residual_blocks.3.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.0.weight -> time_encoder.residual_blocks.4.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.0.bias -> time_encoder.residual_blocks.4.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.1.weight -> time_encoder.residual_blocks.4.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.1.bias -> time_encoder.residual_blocks.4.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.1.running_mean -> time_encoder.residual_blocks.4.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.1.running_var -> time_encoder.residual_blocks.4.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.1.num_batches_tracked -> time_encoder.residual_blocks.4.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.3.weight -> time_encoder.residual_blocks.4.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.3.bias -> time_encoder.residual_blocks.4.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.4.weight -> time_encoder.residual_blocks.4.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.4.bias -> time_encoder.residual_blocks.4.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.4.running_mean -> time_encoder.residual_blocks.4.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.4.running_var -> time_encoder.residual_blocks.4.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.4.num_batches_tracked -> time_encoder.residual_blocks.4.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.5.block.0.weight -> time_encoder.residual_blocks.4.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.5.block.0.bias -> time_encoder.residual_blocks.4.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.5.block.2.weight -> time_encoder.residual_blocks.4.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.time_encoder.residual_blocks.4.block.5.block.2.bias -> time_encoder.residual_blocks.4.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.0.weight -> frequency_encoder.conv_block.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.0.bias -> frequency_encoder.conv_block.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.1.weight -> frequency_encoder.conv_block.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.1.bias -> frequency_encoder.conv_block.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.1.running_mean -> frequency_encoder.conv_block.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.1.running_var -> frequency_encoder.conv_block.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.conv_block.block.1.num_batches_tracked -> frequency_encoder.conv_block.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.0.weight -> frequency_encoder.residual_blocks.0.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.0.bias -> frequency_encoder.residual_blocks.0.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.1.weight -> frequency_encoder.residual_blocks.0.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.1.bias -> frequency_encoder.residual_blocks.0.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.1.running_mean -> frequency_encoder.residual_blocks.0.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.1.running_var -> frequency_encoder.residual_blocks.0.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.1.num_batches_tracked -> frequency_encoder.residual_blocks.0.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.3.weight -> frequency_encoder.residual_blocks.0.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.3.bias -> frequency_encoder.residual_blocks.0.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.4.weight -> frequency_encoder.residual_blocks.0.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.4.bias -> frequency_encoder.residual_blocks.0.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.4.running_mean -> frequency_encoder.residual_blocks.0.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.4.running_var -> frequency_encoder.residual_blocks.0.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.4.num_batches_tracked -> frequency_encoder.residual_blocks.0.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.5.block.0.weight -> frequency_encoder.residual_blocks.0.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.5.block.0.bias -> frequency_encoder.residual_blocks.0.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.5.block.2.weight -> frequency_encoder.residual_blocks.0.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.0.block.5.block.2.bias -> frequency_encoder.residual_blocks.0.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.0.weight -> frequency_encoder.residual_blocks.1.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.0.bias -> frequency_encoder.residual_blocks.1.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.1.weight -> frequency_encoder.residual_blocks.1.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.1.bias -> frequency_encoder.residual_blocks.1.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.1.running_mean -> frequency_encoder.residual_blocks.1.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.1.running_var -> frequency_encoder.residual_blocks.1.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.1.num_batches_tracked -> frequency_encoder.residual_blocks.1.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.3.weight -> frequency_encoder.residual_blocks.1.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.3.bias -> frequency_encoder.residual_blocks.1.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.4.weight -> frequency_encoder.residual_blocks.1.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.4.bias -> frequency_encoder.residual_blocks.1.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.4.running_mean -> frequency_encoder.residual_blocks.1.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.4.running_var -> frequency_encoder.residual_blocks.1.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.4.num_batches_tracked -> frequency_encoder.residual_blocks.1.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.5.block.0.weight -> frequency_encoder.residual_blocks.1.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.5.block.0.bias -> frequency_encoder.residual_blocks.1.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.5.block.2.weight -> frequency_encoder.residual_blocks.1.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.1.block.5.block.2.bias -> frequency_encoder.residual_blocks.1.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.0.weight -> frequency_encoder.residual_blocks.2.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.0.bias -> frequency_encoder.residual_blocks.2.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.1.weight -> frequency_encoder.residual_blocks.2.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.1.bias -> frequency_encoder.residual_blocks.2.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.1.running_mean -> frequency_encoder.residual_blocks.2.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.1.running_var -> frequency_encoder.residual_blocks.2.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.1.num_batches_tracked -> frequency_encoder.residual_blocks.2.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.3.weight -> frequency_encoder.residual_blocks.2.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.3.bias -> frequency_encoder.residual_blocks.2.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.4.weight -> frequency_encoder.residual_blocks.2.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.4.bias -> frequency_encoder.residual_blocks.2.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.4.running_mean -> frequency_encoder.residual_blocks.2.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.4.running_var -> frequency_encoder.residual_blocks.2.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.4.num_batches_tracked -> frequency_encoder.residual_blocks.2.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.5.block.0.weight -> frequency_encoder.residual_blocks.2.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.5.block.0.bias -> frequency_encoder.residual_blocks.2.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.5.block.2.weight -> frequency_encoder.residual_blocks.2.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.2.block.5.block.2.bias -> frequency_encoder.residual_blocks.2.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.0.weight -> frequency_encoder.residual_blocks.3.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.0.bias -> frequency_encoder.residual_blocks.3.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.1.weight -> frequency_encoder.residual_blocks.3.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.1.bias -> frequency_encoder.residual_blocks.3.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.1.running_mean -> frequency_encoder.residual_blocks.3.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.1.running_var -> frequency_encoder.residual_blocks.3.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.1.num_batches_tracked -> frequency_encoder.residual_blocks.3.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.3.weight -> frequency_encoder.residual_blocks.3.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.3.bias -> frequency_encoder.residual_blocks.3.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.4.weight -> frequency_encoder.residual_blocks.3.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.4.bias -> frequency_encoder.residual_blocks.3.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.4.running_mean -> frequency_encoder.residual_blocks.3.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.4.running_var -> frequency_encoder.residual_blocks.3.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.4.num_batches_tracked -> frequency_encoder.residual_blocks.3.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.5.block.0.weight -> frequency_encoder.residual_blocks.3.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.5.block.0.bias -> frequency_encoder.residual_blocks.3.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.5.block.2.weight -> frequency_encoder.residual_blocks.3.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.3.block.5.block.2.bias -> frequency_encoder.residual_blocks.3.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.0.weight -> frequency_encoder.residual_blocks.4.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.0.bias -> frequency_encoder.residual_blocks.4.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.1.weight -> frequency_encoder.residual_blocks.4.block.1.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.1.bias -> frequency_encoder.residual_blocks.4.block.1.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.1.running_mean -> frequency_encoder.residual_blocks.4.block.1.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.1.running_var -> frequency_encoder.residual_blocks.4.block.1.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.1.num_batches_tracked -> frequency_encoder.residual_blocks.4.block.1.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.3.weight -> frequency_encoder.residual_blocks.4.block.3.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.3.bias -> frequency_encoder.residual_blocks.4.block.3.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.4.weight -> frequency_encoder.residual_blocks.4.block.4.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.4.bias -> frequency_encoder.residual_blocks.4.block.4.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.4.running_mean -> frequency_encoder.residual_blocks.4.block.4.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.4.running_var -> frequency_encoder.residual_blocks.4.block.4.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.4.num_batches_tracked -> frequency_encoder.residual_blocks.4.block.4.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.5.block.0.weight -> frequency_encoder.residual_blocks.4.block.5.block.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.5.block.0.bias -> frequency_encoder.residual_blocks.4.block.5.block.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.5.block.2.weight -> frequency_encoder.residual_blocks.4.block.5.block.2.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_encoder.residual_blocks.4.block.5.block.2.bias -> frequency_encoder.residual_blocks.4.block.5.block.2.bias (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.0.weight -> time_projector.projector.0.weight (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.0.bias -> time_projector.projector.0.bias (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.1.module.weight -> time_projector.projector.1.module.weight (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.1.module.bias -> time_projector.projector.1.module.bias (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.1.module.running_mean -> time_projector.projector.1.module.running_mean (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.1.module.running_var -> time_projector.projector.1.module.running_var (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.1.module.num_batches_tracked -> time_projector.projector.1.module.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.3.weight -> time_projector.projector.3.weight (changed: True)\n",
      "\tRenaming key: backbone.time_projector.projector.3.bias -> time_projector.projector.3.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.0.weight -> frequency_projector.projector.0.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.0.bias -> frequency_projector.projector.0.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.1.module.weight -> frequency_projector.projector.1.module.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.1.module.bias -> frequency_projector.projector.1.module.bias (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.1.module.running_mean -> frequency_projector.projector.1.module.running_mean (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.1.module.running_var -> frequency_projector.projector.1.module.running_var (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.1.module.num_batches_tracked -> frequency_projector.projector.1.module.num_batches_tracked (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.3.weight -> frequency_projector.projector.3.weight (changed: True)\n",
      "\tRenaming key: backbone.frequency_projector.projector.3.bias -> frequency_projector.projector.3.bias (changed: True)\n",
      "Model loaded from /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/codecarbon/checkpoints/epoch=2-step=3-v2.ckpt\n"
     ]
    }
   ],
   "source": [
    "backbone = TFC_Backbone(\n",
    "    input_channels=6,\n",
    "    TS_length=60,\n",
    "    single_encoding_size=128,\n",
    "    time_encoder=_ResNet1D(input_shape=(6,60),residual_block_cls=ResNetSEBlock),\n",
    "    frequency_encoder=_ResNet1D(input_shape=(6,60),residual_block_cls=ResNetSEBlock),\n",
    ")\n",
    "\n",
    "\n",
    "backbone = FromPretrained(\n",
    "    model=backbone, \n",
    "    ckpt_path=checkpoint_callback.best_model_path,\n",
    "    filter_keys=[\"backbone\"],\n",
    "    keys_to_rename={\"backbone.\": \"\"},      # Let's remove the prefix from the keys\n",
    "                                        # on the checkpoint to load the model\n",
    "                                        # correctly\n",
    "    strict=True,\n",
    "    error_on_missing_keys=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minerva.models.nets.mlp import MLP\n",
    "head = MLP([256, 128, 6])\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleSupervisedModel(\n",
       "  (backbone): TFC_Backbone(\n",
       "    (time_encoder): _ResNet1D(\n",
       "      (conv_block): ConvolutionalBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv1d(6, 64, kernel_size=(5,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (residual_blocks): Sequential(\n",
       "        (0): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (frequency_encoder): _ResNet1D(\n",
       "      (conv_block): ConvolutionalBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv1d(6, 64, kernel_size=(5,), stride=(1,))\n",
       "          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "      )\n",
       "      (residual_blocks): Sequential(\n",
       "        (0): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResNetSEBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "            (3): Conv1d(32, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "            (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): SqueezeAndExcitation1D(\n",
       "              (block): Sequential(\n",
       "                (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "                (3): Sigmoid()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (global_avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "    )\n",
       "    (time_projector): TFC_Standard_Projector(\n",
       "      (projector): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): IgnoreWhenBatch1(\n",
       "          (module): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (frequency_projector): TFC_Standard_Projector(\n",
       "      (projector): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): IgnoreWhenBatch1(\n",
       "          (module): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc): MLP(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minerva.models.nets.base import SimpleSupervisedModel\n",
    "model = SimpleSupervisedModel(\n",
    "    backbone=backbone,\n",
    "    fc=head,\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    flatten=False,\n",
    "    train_metrics = {\"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6)},\n",
    "    val_metrics = {\"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6)},\n",
    "    test_metrics = {\"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6)}\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 387,590\n",
      "Trainable model parameters: 387,590\n",
      "\n",
      "Backbone:\n",
      "  Total parameters: 353,920\n",
      "  Trainable parameters: 353,920\n",
      "\n",
      "Classification Head:\n",
      "  Total parameters: 33,670\n",
      "  Trainable parameters: 33,670\n",
      "\n",
      "Verification:\n",
      "Backbone + Head total: 387,590\n",
      "Should match total: 387,590\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool1d'>.\n",
      "MACs: 6,264,192,000.0\n",
      "Parameters: 387,590.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Measure ALL model parameters (including backbone AND head)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total model parameters: {total_params:,}\")\n",
    "print(f\"Trainable model parameters: {trainable_params:,}\")\n",
    "\n",
    "# Option 2: Measure components separately (as you intended)\n",
    "# Backbone parameters\n",
    "backbone_total = sum(p.numel() for p in model.backbone.parameters())\n",
    "backbone_trainable = sum(p.numel() for p in model.backbone.parameters() if p.requires_grad)\n",
    "\n",
    "# Head parameters (use model.fc, not head variable)\n",
    "head_total = sum(p.numel() for p in model.fc.parameters())\n",
    "head_trainable = sum(p.numel() for p in model.fc.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nBackbone:\")\n",
    "print(f\"  Total parameters: {backbone_total:,}\")\n",
    "print(f\"  Trainable parameters: {backbone_trainable:,}\")\n",
    "\n",
    "print(f\"\\nClassification Head:\")\n",
    "print(f\"  Total parameters: {head_total:,}\")\n",
    "print(f\"  Trainable parameters: {head_trainable:,}\")\n",
    "\n",
    "# Verify the sum matches Option 1\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Backbone + Head total: {backbone_total + head_total:,}\")\n",
    "print(f\"Should match total: {total_params:,}\")\n",
    "\n",
    "from thop import profile\n",
    "evaluation_data = torch.rand(1000, 6, 60, device='cuda')\n",
    "model.to('cuda')\n",
    "macs, params = profile(model, inputs=(evaluation_data,))\n",
    "\n",
    "print(f\"MACs: {macs:,}\")\n",
    "print(f\"Parameters: {params:,}\")\n",
    "\n",
    "# from codecarbon import EmissionsTracker\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 02:22:58] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 02:22:58] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 02:22:58] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 02:22:59] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 02:22:59] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz\n",
      "[codecarbon WARNING @ 02:22:59] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "[codecarbon INFO @ 02:22:59] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 02:22:59] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 02:22:59] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: cpu_load\n",
      "                GPU Tracking Method: pynvml\n",
      "            \n",
      "[codecarbon INFO @ 02:22:59] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 02:22:59]   Platform system: Linux-6.8.0-65-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 02:22:59]   Python version: 3.10.6\n",
      "[codecarbon INFO @ 02:22:59]   CodeCarbon version: 3.2.1\n",
      "[codecarbon INFO @ 02:22:59]   Available RAM : 62.764 GB\n",
      "[codecarbon INFO @ 02:22:59]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
      "[codecarbon INFO @ 02:22:59]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz\n",
      "[codecarbon INFO @ 02:22:59]   GPU count: 1\n",
      "[codecarbon INFO @ 02:22:59]   GPU model: 1 x NVIDIA RTX 5000 Ada Generation BUT only tracking these GPU ids : ['0']\n",
      "[codecarbon INFO @ 02:23:03] Energy consumed for RAM : 0.000003 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:04] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.017159616 W\n",
      "[codecarbon INFO @ 02:23:04] Energy consumed for All CPU : 0.000001 kWh\n",
      "[codecarbon INFO @ 02:23:04] Energy consumed for all GPUs : 0.000007 kWh. Total GPU Power : 23.356384524102783 W\n",
      "[codecarbon INFO @ 02:23:04] 0.000011 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:04] Energy consumed for RAM : 0.000007 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:05] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.059802048 W\n",
      "[codecarbon INFO @ 02:23:05] Energy consumed for All CPU : 0.000003 kWh\n",
      "[codecarbon INFO @ 02:23:05] Energy consumed for all GPUs : 0.000015 kWh. Total GPU Power : 26.31801237438023 W\n",
      "[codecarbon INFO @ 02:23:05] 0.000024 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:05] Energy consumed for RAM : 0.000010 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:06] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.034167744000001 W\n",
      "[codecarbon INFO @ 02:23:06] Energy consumed for All CPU : 0.000004 kWh\n",
      "[codecarbon INFO @ 02:23:06] Energy consumed for all GPUs : 0.000023 kWh. Total GPU Power : 27.162218964488517 W\n",
      "[codecarbon INFO @ 02:23:06] 0.000037 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:06] Energy consumed for RAM : 0.000013 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:07] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.047412216000001 W\n",
      "[codecarbon INFO @ 02:23:07] Energy consumed for All CPU : 0.000005 kWh\n",
      "[codecarbon INFO @ 02:23:07] Energy consumed for all GPUs : 0.000032 kWh. Total GPU Power : 27.753584099405586 W\n",
      "[codecarbon INFO @ 02:23:07] 0.000050 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:07] Energy consumed for RAM : 0.000016 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:08] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.021654936000001 W\n",
      "[codecarbon INFO @ 02:23:08] Energy consumed for All CPU : 0.000007 kWh\n",
      "[codecarbon INFO @ 02:23:08] Energy consumed for all GPUs : 0.000040 kWh. Total GPU Power : 26.461173607972714 W\n",
      "[codecarbon INFO @ 02:23:08] 0.000062 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:09] Energy consumed for RAM : 0.000019 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:09] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.030375000000001 W\n",
      "[codecarbon INFO @ 02:23:09] Energy consumed for All CPU : 0.000008 kWh\n",
      "[codecarbon INFO @ 02:23:09] Energy consumed for all GPUs : 0.000048 kWh. Total GPU Power : 27.153340740365962 W\n",
      "[codecarbon INFO @ 02:23:09] 0.000075 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:10] Energy consumed for RAM : 0.000022 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:10] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.243 W\n",
      "[codecarbon INFO @ 02:23:10] Energy consumed for All CPU : 0.000009 kWh\n",
      "[codecarbon INFO @ 02:23:10] Energy consumed for all GPUs : 0.000056 kWh. Total GPU Power : 27.4072280849562 W\n",
      "[codecarbon INFO @ 02:23:10] 0.000087 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:11] Energy consumed for RAM : 0.000026 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:11] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.017159616 W\n",
      "[codecarbon INFO @ 02:23:11] Energy consumed for All CPU : 0.000010 kWh\n",
      "[codecarbon INFO @ 02:23:11] Energy consumed for all GPUs : 0.000063 kWh. Total GPU Power : 22.901628945669955 W\n",
      "[codecarbon INFO @ 02:23:11] 0.000099 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:12] Energy consumed for RAM : 0.000029 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:12] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.005334336 W\n",
      "[codecarbon INFO @ 02:23:12] Energy consumed for All CPU : 0.000012 kWh\n",
      "[codecarbon INFO @ 02:23:12] Energy consumed for all GPUs : 0.000070 kWh. Total GPU Power : 23.69669582885436 W\n",
      "[codecarbon INFO @ 02:23:12] 0.000110 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:13] Energy consumed for RAM : 0.000032 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:13] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.054257112 W\n",
      "[codecarbon INFO @ 02:23:13] Energy consumed for All CPU : 0.000013 kWh\n",
      "[codecarbon INFO @ 02:23:13] Energy consumed for all GPUs : 0.000078 kWh. Total GPU Power : 27.987580898929938 W\n",
      "[codecarbon INFO @ 02:23:13] 0.000123 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:14] Energy consumed for RAM : 0.000035 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:14] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.112384512 W\n",
      "[codecarbon INFO @ 02:23:14] Energy consumed for All CPU : 0.000014 kWh\n",
      "[codecarbon INFO @ 02:23:14] Energy consumed for all GPUs : 0.000086 kWh. Total GPU Power : 26.859140256331354 W\n",
      "[codecarbon INFO @ 02:23:14] 0.000135 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:15] Energy consumed for RAM : 0.000038 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:15] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.023652648 W\n",
      "[codecarbon INFO @ 02:23:15] Energy consumed for All CPU : 0.000015 kWh\n",
      "[codecarbon INFO @ 02:23:15] Energy consumed for all GPUs : 0.000093 kWh. Total GPU Power : 23.03388993583247 W\n",
      "[codecarbon INFO @ 02:23:15] 0.000147 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:16] Energy consumed for RAM : 0.000041 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:17] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.078676344000002 W\n",
      "[codecarbon INFO @ 02:23:17] Energy consumed for All CPU : 0.000017 kWh\n",
      "[codecarbon INFO @ 02:23:17] Energy consumed for all GPUs : 0.000100 kWh. Total GPU Power : 23.136939585661224 W\n",
      "[codecarbon INFO @ 02:23:17] 0.000158 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:17] Energy consumed for RAM : 0.000045 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:18] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.016342632 W\n",
      "[codecarbon INFO @ 02:23:18] Energy consumed for All CPU : 0.000018 kWh\n",
      "[codecarbon INFO @ 02:23:18] Energy consumed for all GPUs : 0.000108 kWh. Total GPU Power : 27.206710753798756 W\n",
      "[codecarbon INFO @ 02:23:18] 0.000171 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:23:18] Energy consumed for RAM : 0.000045 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:23:18] Delta energy consumed for CPU with cpu_load : 0.000000 kWh, power : 8.065712456 W\n",
      "[codecarbon INFO @ 02:23:18] Energy consumed for All CPU : 0.000018 kWh\n",
      "[codecarbon INFO @ 02:23:18] Energy consumed for all GPUs : 0.000115 kWh. Total GPU Power : 48.53565841417952 W\n",
      "[codecarbon INFO @ 02:23:18] 0.000178 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_mWh</th>\n",
       "      <th>energy_J</th>\n",
       "      <th>emissions_mgCO2eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>46.15</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>45.80</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>45.31</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>44.61</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>44.60</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>41.34</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>41.38</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>45.53</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>45.74</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>39.77</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>44.02</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      energy_mWh  energy_J  emissions_mgCO2eq\n",
       "2           0.01     46.15               1.26\n",
       "3           0.01     45.80               1.25\n",
       "4           0.01     45.31               1.24\n",
       "5           0.01     44.61               1.22\n",
       "6           0.01     44.60               1.22\n",
       "7           0.01     41.34               1.13\n",
       "8           0.01     41.38               1.13\n",
       "9           0.01     45.53               1.24\n",
       "10          0.01     45.74               1.25\n",
       "11          0.01     39.77               1.09\n",
       "mean        0.01     44.02               1.20\n",
       "std         0.00      2.30               0.06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "TOTAL_RUNS = 14\n",
    "DISCARD_FIRST = 2\n",
    "DISCARD_LAST = 2\n",
    "\n",
    "results = []\n",
    "\n",
    "tracker = EmissionsTracker(\n",
    "    project_name=\"basic_measurement\",\n",
    "    measure_power_secs=10,\n",
    "    save_to_file=False\n",
    ")\n",
    "\n",
    "try:\n",
    "    for run_id in range(TOTAL_RUNS):\n",
    "        tracker.start_task(f\"measure_inference_{run_id}\")\n",
    "\n",
    "        _ = model(evaluation_data)  # inference\n",
    "\n",
    "        emissions = tracker.stop_task()\n",
    "\n",
    "        energy_kwh = emissions.energy_consumed\n",
    "        energy_mwh = energy_kwh * 1_000          # kWh → mWh\n",
    "        energy_j   = energy_kwh * 3_600_000      # kWh → J\n",
    "        emissions_g = emissions.emissions * 1_000 * 1_000  # kg → g→ mg\n",
    "\n",
    "        results.append({\n",
    "            \"run\": run_id,\n",
    "            \"energy_mWh\": energy_mwh,\n",
    "            \"energy_J\": energy_j,\n",
    "            \"emissions_mgCO2eq\": emissions_g,\n",
    "            # \"duration_s\": emissions.duration\n",
    "        })\n",
    "\n",
    "finally:\n",
    "    tracker.stop()\n",
    "\n",
    "# --- All runs ---\n",
    "df_all = pd.DataFrame(results)\n",
    "\n",
    "# --- Valid runs (ignore first & last 2) ---\n",
    "df_valid = df_all.iloc[DISCARD_FIRST: TOTAL_RUNS - DISCARD_LAST]\n",
    "\n",
    "# --- Statistics ---\n",
    "mean = df_valid[[\"energy_mWh\", \"energy_J\", \"emissions_mgCO2eq\"]].mean()\n",
    "std  = df_valid[[\"energy_mWh\", \"energy_J\", \"emissions_mgCO2eq\"]].std()\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    [mean, std],\n",
    "    index=[\"mean\", \"std\"]\n",
    ").round(2)\n",
    "\n",
    "# --- Final table ---\n",
    "df_final = pd.concat([\n",
    "    df_valid.set_index(\"run\").round(2),\n",
    "    summary\n",
    "])\n",
    "\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the Pytorch Lightning Trainer Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x7f8d937fd0c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\", monitor=\"val_loss\", mode=\"min\", save_last=True\n",
    ")\n",
    "\n",
    "## Logger\n",
    "logger = CSVLogger(\n",
    "    save_dir=log_dir, name=\"tfc-cnn-pff-finetune\", version=execution_id\n",
    ")\n",
    "\n",
    "## Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # Only for testing. Remove for production. We will only train using 1 batch\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the fine-tuning pipeline (and running the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " cuda device: \n",
      "\n",
      "\n",
      " NVIDIA RTX A5000\n",
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/logs/run_20250220-180053\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/logs/run_20250220-180053/run_2025-02-20-18-01-05425cfb5b1f52406bb97f1fd70f7f680c.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | backbone | TFC_Backbone     | 312 K  | train\n",
      "1 | fc       | MLP              | 33.7 K | train\n",
      "2 | loss_fn  | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "345 K     Trainable params\n",
      "0         Non-trainable params\n",
      "345 K     Total params\n",
      "1.383     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Using DataLoader with shuffle=False\n",
      "Using DataLoader with shuffle=True                                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0053, val_loss=1.890, val_acc=0.000, train_loss=1.760, train_acc=0.203]        "
     ]
    }
   ],
   "source": [
    "train_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42\n",
    ")\n",
    "train_pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " cuda device: \n",
      "\n",
      "\n",
      " NVIDIA RTX A5000\n",
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/logs/run_20250218-153350\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/logs/run_20250218-153350/run_2025-02-18-15-34-264861ecddd0514e28b1dbbc91a7f03eae.yaml\n",
      "Using DataLoader with shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/checkpoints/epoch=0-step=1-v1.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "Loaded model weights from the checkpoint at /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/checkpoints/epoch=0-step=1-v1.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=False\n",
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 50.22it/s]\n",
      "Running classification metrics...\n",
      "Metrics saved to /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/logs/run_20250218-153350/metrics_2025-02-18-15-34-264861ecddd0514e28b1dbbc91a7f03eae.yaml\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tfc/logs/run_20250218-153350/run_2025-02-18-15-34-264861ecddd0514e28b1dbbc91a7f03eae.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/minerva/analysis/metrics/balanced_accuracy.py:59: UserWarning: y_pred contains nan values and not all classes passed\n",
      "  warnings.warn(f\"y_pred contains nan values and not all classes passed\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classification': {'accuracy': [0.16760829091072083],\n",
       "  'f1': [0.16760829091072083],\n",
       "  'precision': [0.16760829091072083],\n",
       "  'recall': [0.16760829091072083],\n",
       "  'balanced_accuracy': [0.3334905505180359]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42,\n",
    "    classification_metrics={\n",
    "        \"accuracy\": torchmetrics.Accuracy(num_classes=6, task=\"multiclass\"),\n",
    "        \"f1\": torchmetrics.F1Score(num_classes=6, task=\"multiclass\"),\n",
    "        \"precision\": torchmetrics.Precision(num_classes=6, task=\"multiclass\"),\n",
    "        \"recall\": torchmetrics.Recall(num_classes=6, task=\"multiclass\"),\n",
    "        \"balanced_accuracy\": BalancedAccuracy(num_classes=6, task=\"multiclass\"),\n",
    "    },\n",
    "    apply_metrics_per_sample=False,\n",
    "    # model_analysis={\n",
    "    #     \"tsne\": TSNEAnalysis(\n",
    "    #         height=800,\n",
    "    #         width=800,\n",
    "    #         legend_title=\"Activity\",\n",
    "    #         title=\"t-SNE of TFC Finetuned on MotionSense\",\n",
    "    #         output_filename=\"tsne_tfc_finetuned_motionsense.pdf\",\n",
    "    #         label_names={\n",
    "    #             0: \"sit\",\n",
    "    #             1: \"stand\",\n",
    "    #             2: \"walk\",\n",
    "    #             3: \"stair up\",\n",
    "    #             4: \"stair down\",\n",
    "    #             5: \"run\",\n",
    "    #             6: \"stair up and down\",\n",
    "    #         },\n",
    "    #     )\n",
    "    # },\n",
    ")\n",
    "\n",
    "test_pipeline.run(\n",
    "    data_module, task=\"evaluate\", ckpt_path=checkpoint_callback.best_model_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
