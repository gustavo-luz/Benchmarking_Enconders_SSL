{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Neighbourhood Coding (TNC) + CNN PFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "from minerva.data.data_modules.har import MultiModalHARSeriesDataModule\n",
    "from minerva.analysis.metrics.balanced_accuracy import BalancedAccuracy\n",
    "from minerva.analysis.model_analysis import TSNEAnalysis\n",
    "from minerva.models.nets.time_series.cnns import CNN_PF_Backbone\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "\n",
    "from minerva.models.ssl.tnc import TNC\n",
    "from minerva.models.nets.tnc import Discriminator_TNC\n",
    "from minerva.data.data_modules.har_xu_23 import HarDataModule\n",
    "from datetime import datetime\n",
    "import lightning as L\n",
    "import torch\n",
    "import torchmetrics\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from minerva.analysis.metrics.balanced_accuracy import BalancedAccuracy\n",
    "from minerva.analysis.model_analysis import TSNEAnalysis\n",
    "from minerva.data.data_modules.har import MultiModalHARSeriesDataModule\n",
    "from minerva.data.data_modules.har_rodrigues_24 import HARDataModuleCPC\n",
    "from minerva.models.loaders import FromPretrained\n",
    "from minerva.models.nets.base import SimpleSupervisedModel\n",
    "from minerva.models.nets.cpc_networks import HARCPCAutoregressive\n",
    "from minerva.models.nets.mlp import MLP\n",
    "from minerva.models.nets.time_series.cnns import CNN_PF_Backbone\n",
    "from minerva.models.ssl.cpc import CPC\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution ID: run_20260127-023233\n",
      "Log dir: ./logs/run_20260127-023233\n"
     ]
    }
   ],
   "source": [
    "execution_id = f'run_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "log_dir = f\"./logs/{execution_id}\" \n",
    "\n",
    "print(f\"Execution ID: {execution_id}\")\n",
    "print(f\"Log dir: {log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training with TNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minerva.data.data_modules.har_xu_23.HarDataModule at 0x75c7d8a473a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = HarDataModule(\n",
    "    # processed_data_dir=\"/workspaces/HIAAC-KR-Dev-Container/shared_data/authentication/standartized_balanced/RecodGait_v1_TNC\",\n",
    "    processed_data_dir=\"//workspaces/HIAAC-KR-Dev-Container/shared_data/xu_2023_datasets/1-1/kuhar/processed/\",\n",
    "    window_size=60,\n",
    "    batch_size=16,\n",
    "    adf=False,\n",
    ")\n",
    "\n",
    "data_module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining TNC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple forward pass to check the output shape\n",
    "data_module.setup(\"fit\")\n",
    "dataset = data_module.train_dataloader()\n",
    "batch = next(iter(dataset))\n",
    "\n",
    "# Create a backbone model\n",
    "g_enc = CNN_PF_Backbone(include_middle=True, permute=True,flatten=True)\n",
    "r = g_enc.forward(batch[0])\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TNC(\n",
       "  (backbone): CNN_PF_Backbone(\n",
       "    (first_padder): ZeroPadder2D(pad_at=(3,), padding_size=2)\n",
       "    (upper_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (lower_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (middle_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (shared_part): Sequential(\n",
       "      (0): Conv2d(48, 64, kernel_size=(3, 5), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (projection_head): Discriminator_TNC(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=3072, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TNC(\n",
    "    backbone=g_enc,\n",
    "    projection_head=Discriminator_TNC(\n",
    "        # input_size=r.shape[-1],\n",
    "        input_size=768,\n",
    "        max_pool=False\n",
    "    ),\n",
    "    w=0.2\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the Pytorch Lightning Trainer Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x75c7d0888fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "## Logger\n",
    "logger = CSVLogger(save_dir=log_dir, name='tnc-cnn-pff-pretraining', version=execution_id)\n",
    "\n",
    "## Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # Only for testing. Remove for production. We will only train using 1 batch\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the training pipeline (and running the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Seed set to: 42 **\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/codecarbon/logs/run_20260127-023233/run_2026-01-27-02-32-3409fc2a17.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type              | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | CNN_PF_Backbone   | 46.6 K | train\n",
      "1 | projection_head | Discriminator_TNC | 4.7 M  | train\n",
      "2 | loss_fn         | BCEWithLogitsLoss | 0      | train\n",
      "--------------------------------------------------------------\n",
      "4.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 M     Total params\n",
      "19.085    Total estimated model params size (MB)\n",
      "25        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
      "\n",
      "\n",
      " Logging timestamp - Train Loss: 0.6848717927932739,\n",
      "\n",
      " \n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=3233]        \n",
      "\n",
      "\n",
      " Logging timestamp - Train Loss: 0.6827762722969055,\n",
      "\n",
      " \n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=3233]        \n",
      "\n",
      "\n",
      " Logging timestamp - Train Loss: 0.6871581077575684,\n",
      "\n",
      " \n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=3233]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:01<00:00,  0.50it/s, v_num=3233]\n",
      "⏱️ fit took 8.25s → saved to /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/codecarbon/logs/run_20260127-023233/timings_fit.csv\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/codecarbon/logs/run_20260127-023233/run_2026-01-27-02-32-3409fc2a17.yaml\n"
     ]
    }
   ],
   "source": [
    "train_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42\n",
    ")\n",
    "train_pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Inspecting checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backbone.upper_part.0.weight',\n",
       " 'backbone.upper_part.0.bias',\n",
       " 'backbone.lower_part.0.weight',\n",
       " 'backbone.lower_part.0.bias',\n",
       " 'backbone.middle_part.0.weight',\n",
       " 'backbone.middle_part.0.bias',\n",
       " 'backbone.shared_part.0.weight',\n",
       " 'backbone.shared_part.0.bias',\n",
       " 'projection_head.model.0.weight',\n",
       " 'projection_head.model.0.bias',\n",
       " 'projection_head.model.3.weight',\n",
       " 'projection_head.model.3.bias']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = checkpoint_callback.last_model_path\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cuda\")\n",
    "ckpt = ckpt.get(\"state_dict\", ckpt)\n",
    "list(ckpt.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tunning with CNN PFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining the Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiModalHARSeriesDataModule(data_path=/workspaces/HIAAC-KR-Dev-Container/shared_data/daghar/standardized_view/MotionSense, batch_size=64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = MultiModalHARSeriesDataModule(\n",
    "    data_path=\"/workspaces/HIAAC-KR-Dev-Container/shared_data/daghar/standardized_view/MotionSense/\",\n",
    "    feature_prefixes=[\"accel-x\", \"accel-y\", \"accel-z\", \"gyro-x\", \"gyro-y\", \"gyro-z\"],\n",
    "    label=\"standard activity code\",\n",
    "    features_as_channels=True,\n",
    "    cast_to=\"float32\",\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=True\n",
      "Using DataLoader with shuffle=False\n",
      "torch.Size([64, 6, 60]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Pega os dataloaders de treino e validação\n",
    "data_module.setup(\"fit\")\n",
    "train_data_loader = data_module.train_dataloader()\n",
    "validation_data_loader = data_module.val_dataloader()\n",
    "first_batch = next(iter(train_data_loader))\n",
    "\n",
    "X, y = first_batch\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the CNN PFF Model for Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing key renaming with: {'backbone.': ''}\n",
      "\tRenaming key: backbone.upper_part.0.weight -> upper_part.0.weight (changed: True)\n",
      "\tRenaming key: backbone.upper_part.0.bias -> upper_part.0.bias (changed: True)\n",
      "\tRenaming key: backbone.lower_part.0.weight -> lower_part.0.weight (changed: True)\n",
      "\tRenaming key: backbone.lower_part.0.bias -> lower_part.0.bias (changed: True)\n",
      "\tRenaming key: backbone.middle_part.0.weight -> middle_part.0.weight (changed: True)\n",
      "\tRenaming key: backbone.middle_part.0.bias -> middle_part.0.bias (changed: True)\n",
      "\tRenaming key: backbone.shared_part.0.weight -> shared_part.0.weight (changed: True)\n",
      "\tRenaming key: backbone.shared_part.0.bias -> shared_part.0.bias (changed: True)\n",
      "Model loaded from /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/codecarbon/checkpoints/epoch=0-step=1.ckpt\n"
     ]
    }
   ],
   "source": [
    "backbone = CNN_PF_Backbone(include_middle=True, permute=False,flatten=True)\n",
    "backbone = FromPretrained(\n",
    "    model=backbone, \n",
    "    ckpt_path=checkpoint_callback.best_model_path,\n",
    "    filter_keys=[\"backbone\"],\n",
    "    keys_to_rename={\"backbone.\": \"\"},      # Let's remove the prefix from the keys\n",
    "                                        # on the checkpoint to load the model\n",
    "                                        # correctly\n",
    "    strict=True,\n",
    "    error_on_missing_keys=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy forward pass to check the output shape\n",
    "r = backbone.forward(X)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = MLP([\n",
    "    768,  # r.shape[1]*r.shape[2],  (64*12)\n",
    "    128, \n",
    "    6\n",
    "])\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleSupervisedModel(\n",
       "  (backbone): CNN_PF_Backbone(\n",
       "    (first_padder): ZeroPadder2D(pad_at=(3,), padding_size=2)\n",
       "    (upper_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (lower_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (middle_part): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (shared_part): Sequential(\n",
       "      (0): Conv2d(48, 64, kernel_size=(3, 5), stride=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(2, 3), stride=(2, 3), padding=1, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): MLP(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleSupervisedModel(\n",
    "    backbone=backbone,\n",
    "    fc=head,\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    flatten=False,\n",
    "    train_metrics={\n",
    "        \"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6),\n",
    "    },\n",
    "    val_metrics={\n",
    "        \"acc\": torchmetrics.Accuracy(task=\"multiclass\", num_classes=6),\n",
    "    },\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 145,830\n",
      "Trainable model parameters: 145,830\n",
      "\n",
      "Backbone:\n",
      "  Total parameters: 46,624\n",
      "  Trainable parameters: 46,624\n",
      "\n",
      "Classification Head:\n",
      "  Total parameters: 99,206\n",
      "  Trainable parameters: 99,206\n",
      "\n",
      "Verification:\n",
      "Backbone + Head total: 145,830\n",
      "Should match total: 145,830\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "MACs: 1,673,856,000.0\n",
      "Parameters: 145,830.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Measure ALL model parameters (including backbone AND head)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total model parameters: {total_params:,}\")\n",
    "print(f\"Trainable model parameters: {trainable_params:,}\")\n",
    "\n",
    "# Option 2: Measure components separately (as you intended)\n",
    "# Backbone parameters\n",
    "backbone_total = sum(p.numel() for p in model.backbone.parameters())\n",
    "backbone_trainable = sum(p.numel() for p in model.backbone.parameters() if p.requires_grad)\n",
    "\n",
    "# Head parameters (use model.fc, not head variable)\n",
    "head_total = sum(p.numel() for p in model.fc.parameters())\n",
    "head_trainable = sum(p.numel() for p in model.fc.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nBackbone:\")\n",
    "print(f\"  Total parameters: {backbone_total:,}\")\n",
    "print(f\"  Trainable parameters: {backbone_trainable:,}\")\n",
    "\n",
    "print(f\"\\nClassification Head:\")\n",
    "print(f\"  Total parameters: {head_total:,}\")\n",
    "print(f\"  Trainable parameters: {head_trainable:,}\")\n",
    "\n",
    "# Verify the sum matches Option 1\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Backbone + Head total: {backbone_total + head_total:,}\")\n",
    "print(f\"Should match total: {total_params:,}\")\n",
    "\n",
    "from thop import profile\n",
    "evaluation_data = torch.rand(1000, 6, 60, device='cuda')\n",
    "model.to('cuda')\n",
    "macs, params = profile(model, inputs=(evaluation_data,))\n",
    "\n",
    "print(f\"MACs: {macs:,}\")\n",
    "print(f\"Parameters: {params:,}\")\n",
    "\n",
    "# from codecarbon import EmissionsTracker\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 02:32:46] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon INFO @ 02:32:46] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 02:32:46] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 02:32:47] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 02:32:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz\n",
      "[codecarbon WARNING @ 02:32:47] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "[codecarbon INFO @ 02:32:47] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 02:32:47] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 02:32:47] The below tracking methods have been set up:\n",
      "                RAM Tracking Method: RAM power estimation model\n",
      "                CPU Tracking Method: cpu_load\n",
      "                GPU Tracking Method: pynvml\n",
      "            \n",
      "[codecarbon INFO @ 02:32:47] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 02:32:47]   Platform system: Linux-6.8.0-65-generic-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 02:32:47]   Python version: 3.10.6\n",
      "[codecarbon INFO @ 02:32:47]   CodeCarbon version: 3.2.1\n",
      "[codecarbon INFO @ 02:32:47]   Available RAM : 62.764 GB\n",
      "[codecarbon INFO @ 02:32:47]   CPU count: 12 thread(s) in 1 physical CPU(s)\n",
      "[codecarbon INFO @ 02:32:47]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz\n",
      "[codecarbon INFO @ 02:32:47]   GPU count: 1\n",
      "[codecarbon INFO @ 02:32:47]   GPU model: 1 x NVIDIA RTX 5000 Ada Generation BUT only tracking these GPU ids : ['0']\n",
      "[codecarbon INFO @ 02:32:51] Energy consumed for RAM : 0.000003 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:51] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.016342632 W\n",
      "[codecarbon INFO @ 02:32:51] Energy consumed for All CPU : 0.000001 kWh\n",
      "[codecarbon INFO @ 02:32:51] Energy consumed for all GPUs : 0.000006 kWh. Total GPU Power : 22.840571345530137 W\n",
      "[codecarbon INFO @ 02:32:51] 0.000010 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:52] Energy consumed for RAM : 0.000006 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:52] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.666792000000001 W\n",
      "[codecarbon INFO @ 02:32:52] Energy consumed for All CPU : 0.000002 kWh\n",
      "[codecarbon INFO @ 02:32:52] Energy consumed for all GPUs : 0.000013 kWh. Total GPU Power : 23.331365545734318 W\n",
      "[codecarbon INFO @ 02:32:52] 0.000021 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:53] Energy consumed for RAM : 0.000008 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:53] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.088203096 W\n",
      "[codecarbon INFO @ 02:32:53] Energy consumed for All CPU : 0.000003 kWh\n",
      "[codecarbon INFO @ 02:32:53] Energy consumed for all GPUs : 0.000020 kWh. Total GPU Power : 23.756877885566645 W\n",
      "[codecarbon INFO @ 02:32:53] 0.000032 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:54] Energy consumed for RAM : 0.000011 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:54] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.106671168 W\n",
      "[codecarbon INFO @ 02:32:54] Energy consumed for All CPU : 0.000005 kWh\n",
      "[codecarbon INFO @ 02:32:54] Energy consumed for all GPUs : 0.000026 kWh. Total GPU Power : 23.889988284521227 W\n",
      "[codecarbon INFO @ 02:32:54] 0.000042 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:55] Energy consumed for RAM : 0.000014 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:55] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.161862552 W\n",
      "[codecarbon INFO @ 02:32:55] Energy consumed for All CPU : 0.000006 kWh\n",
      "[codecarbon INFO @ 02:32:55] Energy consumed for all GPUs : 0.000035 kWh. Total GPU Power : 29.351740355961677 W\n",
      "[codecarbon INFO @ 02:32:55] 0.000054 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:56] Energy consumed for RAM : 0.000017 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:56] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.478416384 W\n",
      "[codecarbon INFO @ 02:32:56] Energy consumed for All CPU : 0.000007 kWh\n",
      "[codecarbon INFO @ 02:32:56] Energy consumed for all GPUs : 0.000041 kWh. Total GPU Power : 24.67249870539944 W\n",
      "[codecarbon INFO @ 02:32:56] 0.000065 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:57] Energy consumed for RAM : 0.000020 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:57] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.214990848 W\n",
      "[codecarbon INFO @ 02:32:57] Energy consumed for All CPU : 0.000008 kWh\n",
      "[codecarbon INFO @ 02:32:57] Energy consumed for all GPUs : 0.000048 kWh. Total GPU Power : 24.096715385291358 W\n",
      "[codecarbon INFO @ 02:32:57] 0.000076 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:58] Energy consumed for RAM : 0.000022 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:58] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.379297728000001 W\n",
      "[codecarbon INFO @ 02:32:58] Energy consumed for All CPU : 0.000009 kWh\n",
      "[codecarbon INFO @ 02:32:58] Energy consumed for all GPUs : 0.000055 kWh. Total GPU Power : 24.441152805918737 W\n",
      "[codecarbon INFO @ 02:32:58] 0.000087 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:32:59] Energy consumed for RAM : 0.000025 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:32:59] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.085753152 W\n",
      "[codecarbon INFO @ 02:32:59] Energy consumed for All CPU : 0.000010 kWh\n",
      "[codecarbon INFO @ 02:32:59] Energy consumed for all GPUs : 0.000062 kWh. Total GPU Power : 23.783078062169285 W\n",
      "[codecarbon INFO @ 02:32:59] 0.000097 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:33:00] Energy consumed for RAM : 0.000028 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:33:00] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.083349 W\n",
      "[codecarbon INFO @ 02:33:00] Energy consumed for All CPU : 0.000012 kWh\n",
      "[codecarbon INFO @ 02:33:00] Energy consumed for all GPUs : 0.000068 kWh. Total GPU Power : 24.008179684009956 W\n",
      "[codecarbon INFO @ 02:33:00] 0.000108 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:33:01] Energy consumed for RAM : 0.000031 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:33:01] Delta energy consumed for CPU with cpu_load : 0.000002 kWh, power : 10.930946048000004 W\n",
      "[codecarbon INFO @ 02:33:01] Energy consumed for All CPU : 0.000013 kWh\n",
      "[codecarbon INFO @ 02:33:01] Energy consumed for all GPUs : 0.000075 kWh. Total GPU Power : 23.39555964920614 W\n",
      "[codecarbon INFO @ 02:33:01] 0.000119 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:33:02] Energy consumed for RAM : 0.000034 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:33:02] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.201831912000001 W\n",
      "[codecarbon INFO @ 02:33:02] Energy consumed for All CPU : 0.000014 kWh\n",
      "[codecarbon INFO @ 02:33:02] Energy consumed for all GPUs : 0.000082 kWh. Total GPU Power : 23.656094454062366 W\n",
      "[codecarbon INFO @ 02:33:02] 0.000130 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:33:03] Energy consumed for RAM : 0.000036 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:33:03] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.206156736000004 W\n",
      "[codecarbon INFO @ 02:33:03] Energy consumed for All CPU : 0.000015 kWh\n",
      "[codecarbon INFO @ 02:33:03] Energy consumed for all GPUs : 0.000090 kWh. Total GPU Power : 28.887677907163305 W\n",
      "[codecarbon INFO @ 02:33:03] 0.000142 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:33:04] Energy consumed for RAM : 0.000039 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:33:04] Delta energy consumed for CPU with cpu_load : 0.000001 kWh, power : 8.257873544 W\n",
      "[codecarbon INFO @ 02:33:04] Energy consumed for All CPU : 0.000017 kWh\n",
      "[codecarbon INFO @ 02:33:04] Energy consumed for all GPUs : 0.000097 kWh. Total GPU Power : 23.94036701385243 W\n",
      "[codecarbon INFO @ 02:33:04] 0.000152 kWh of electricity and 0.000000 L of water were used since the beginning.\n",
      "[codecarbon INFO @ 02:33:04] Energy consumed for RAM : 0.000039 kWh. RAM Power : 20.0 W\n",
      "[codecarbon INFO @ 02:33:05] Delta energy consumed for CPU with cpu_load : 0.000000 kWh, power : 8.219501000000001 W\n",
      "[codecarbon INFO @ 02:33:05] Energy consumed for All CPU : 0.000017 kWh\n",
      "[codecarbon INFO @ 02:33:05] Energy consumed for all GPUs : 0.000103 kWh. Total GPU Power : 49.173733980640854 W\n",
      "[codecarbon INFO @ 02:33:05] 0.000159 kWh of electricity and 0.000000 L of water were used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_mWh</th>\n",
       "      <th>energy_J</th>\n",
       "      <th>emissions_mgCO2eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.24</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.36</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>43.80</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>39.33</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.56</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.97</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.18</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.60</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>39.21</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>38.09</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.01</td>\n",
       "      <td>39.14</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      energy_mWh  energy_J  emissions_mgCO2eq\n",
       "2           0.01     38.24               1.04\n",
       "3           0.01     38.36               1.05\n",
       "4           0.01     43.80               1.20\n",
       "5           0.01     39.33               1.07\n",
       "6           0.01     38.56               1.05\n",
       "7           0.01     38.97               1.06\n",
       "8           0.01     38.18               1.04\n",
       "9           0.01     38.60               1.05\n",
       "10          0.01     39.21               1.07\n",
       "11          0.01     38.09               1.04\n",
       "mean        0.01     39.14               1.07\n",
       "std         0.00      1.70               0.05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "TOTAL_RUNS = 14\n",
    "DISCARD_FIRST = 2\n",
    "DISCARD_LAST = 2\n",
    "\n",
    "results = []\n",
    "\n",
    "tracker = EmissionsTracker(\n",
    "    project_name=\"basic_measurement\",\n",
    "    measure_power_secs=10,\n",
    "    save_to_file=False\n",
    ")\n",
    "\n",
    "try:\n",
    "    for run_id in range(TOTAL_RUNS):\n",
    "        tracker.start_task(f\"measure_inference_{run_id}\")\n",
    "\n",
    "        _ = model(evaluation_data)  # inference\n",
    "\n",
    "        emissions = tracker.stop_task()\n",
    "\n",
    "        energy_kwh = emissions.energy_consumed\n",
    "        energy_mwh = energy_kwh * 1_000          # kWh → mWh\n",
    "        energy_j   = energy_kwh * 3_600_000      # kWh → J\n",
    "        emissions_g = emissions.emissions * 1_000 * 1_000  # kg → g→ mg\n",
    "\n",
    "        results.append({\n",
    "            \"run\": run_id,\n",
    "            \"energy_mWh\": energy_mwh,\n",
    "            \"energy_J\": energy_j,\n",
    "            \"emissions_mgCO2eq\": emissions_g,\n",
    "            # \"duration_s\": emissions.duration\n",
    "        })\n",
    "\n",
    "finally:\n",
    "    tracker.stop()\n",
    "\n",
    "# --- All runs ---\n",
    "df_all = pd.DataFrame(results)\n",
    "\n",
    "# --- Valid runs (ignore first & last 2) ---\n",
    "df_valid = df_all.iloc[DISCARD_FIRST: TOTAL_RUNS - DISCARD_LAST]\n",
    "\n",
    "# --- Statistics ---\n",
    "mean = df_valid[[\"energy_mWh\", \"energy_J\", \"emissions_mgCO2eq\"]].mean()\n",
    "std  = df_valid[[\"energy_mWh\", \"energy_J\", \"emissions_mgCO2eq\"]].std()\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    [mean, std],\n",
    "    index=[\"mean\", \"std\"]\n",
    ").round(2)\n",
    "\n",
    "# --- Final table ---\n",
    "df_final = pd.concat([\n",
    "    df_valid.set_index(\"run\").round(2),\n",
    "    summary\n",
    "])\n",
    "\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining the Pytorch Lightning Trainer Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.trainer.trainer.Trainer at 0x7f0110bb3910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "## Logger\n",
    "logger = CSVLogger(save_dir=log_dir, name='tnc-cnn-pff-finetune', version=execution_id)\n",
    "\n",
    "## Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # Only for testing. Remove for production. We will only train using 1 batch\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    ")\n",
    "\n",
    "trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating the fine-tuning pipeline (and running the training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " cuda device: \n",
      "\n",
      "\n",
      " NVIDIA RTX A5000\n",
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/run_2025-02-18-18-48-317ba4bd2be4bb4d56bc09042f0f3f441f.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | backbone | CNN_PF_Backbone  | 46.6 K | train\n",
      "1 | fc       | MLP              | 99.2 K | train\n",
      "2 | loss_fn  | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "145 K     Trainable params\n",
      "0         Non-trainable params\n",
      "145 K     Total params\n",
      "0.583     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]Using DataLoader with shuffle=False\n",
      "Using DataLoader with shuffle=True                                         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:07<00:00,  0.14it/s, v_num=4817, val_loss=1.860, val_acc=0.000, train_loss=1.500, train_acc=0.203]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:07<00:00,  0.14it/s, v_num=4817, val_loss=1.860, val_acc=0.000, train_loss=1.500, train_acc=0.203]\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/run_2025-02-18-18-48-317ba4bd2be4bb4d56bc09042f0f3f441f.yaml\n"
     ]
    }
   ],
   "source": [
    "train_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42\n",
    ")\n",
    "train_pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " cuda device: \n",
      "\n",
      "\n",
      " NVIDIA RTX A5000\n",
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/run_2025-02-18-18-48-57fdd9388fc5334ddbbdcdbaa07d500e7a.yaml\n",
      "Using DataLoader with shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/checkpoints/epoch=1-step=2.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "Loaded model weights from the checkpoint at /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/checkpoints/epoch=1-step=2.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=False\n",
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 218.47it/s]\n",
      "Running classification metrics...\n",
      "Running model analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/minerva/analysis/metrics/balanced_accuracy.py:59: UserWarning: y_pred contains nan values and not all classes passed\n",
      "  warnings.warn(f\"y_pred contains nan values and not all classes passed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DataLoader with shuffle=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/minerva/analysis/model_analysis.py:118: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  X = torch.tensor(X, device=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-SNE plot saved to /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/tsne_cpc_finetuned_motionsense.pdf\n",
      "Metrics saved to /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/metrics_2025-02-18-18-48-57fdd9388fc5334ddbbdcdbaa07d500e7a.yaml\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/run_2025-02-18-18-48-57fdd9388fc5334ddbbdcdbaa07d500e7a.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classification': {'accuracy': [0.1666666716337204],\n",
       "  'f1': [0.1666666716337204],\n",
       "  'precision': [0.1666666716337204],\n",
       "  'recall': [0.1666666716337204],\n",
       "  'balanced_accuracy': [0.08349056541919708]},\n",
       " 'analysis': {'tsne': '/workspaces/HIAAC-KR-Dev-Container/Minerva-Exps/benchmarks/experiments/docs/tnc/logs/run_20250218-184817/tsne_cpc_finetuned_motionsense.pdf'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir,\n",
    "    save_run_status=True,\n",
    "    seed=42,\n",
    "    classification_metrics={\n",
    "        \"accuracy\": torchmetrics.Accuracy(num_classes=6, task=\"multiclass\"),\n",
    "        \"f1\": torchmetrics.F1Score(num_classes=6, task=\"multiclass\"),\n",
    "        \"precision\": torchmetrics.Precision(num_classes=6, task=\"multiclass\"),\n",
    "        \"recall\": torchmetrics.Recall(num_classes=6, task=\"multiclass\"),\n",
    "        \"balanced_accuracy\": BalancedAccuracy(num_classes=6, task=\"multiclass\"),\n",
    "    },\n",
    "    apply_metrics_per_sample=False,\n",
    "    model_analysis={\n",
    "        \"tsne\": TSNEAnalysis(\n",
    "            height=800,\n",
    "            width=800,\n",
    "            legend_title=\"Activity\",\n",
    "            title=\"t-SNE of CPC Finetuned on MotionSense\",\n",
    "            output_filename=\"tsne_cpc_finetuned_motionsense.pdf\",\n",
    "            label_names={\n",
    "                0: \"sit\",\n",
    "                1: \"stand\",\n",
    "                2: \"walk\",\n",
    "                3: \"stair up\",\n",
    "                4: \"stair down\",\n",
    "                5: \"run\",\n",
    "                6: \"stair up and down\",\n",
    "            },\n",
    "        )\n",
    "    },\n",
    ")\n",
    "\n",
    "test_pipeline.run(\n",
    "    data_module, task=\"evaluate\", ckpt_path=checkpoint_callback.best_model_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
