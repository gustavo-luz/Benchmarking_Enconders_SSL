model: null                 # (???) It will be overwritten dinamically (model/file_path, from CSV)
trainer:
  class_path: lightning.Trainer
  init_args:
    accelerator: gpu        # The accelerator to use.
    devices: 1              # Number of GPUs to use (when using GPU).
    strategy: auto          # Strategy to use for distributed training.
    max_epochs: 100          # Number of epochs to train.
    benchmark: True         # If true enables cudnn.benchmark.
    logger:
      class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        flush_logs_every_n_steps: 1
        save_dir: null      # (???) It will be overwritten dinamically (log_dir, from schemas.py)
        name: null          # (???) It will be overwritten dinamically (execution/uid, from CSV)
        version: null       # (???) It will be overwritten dinamically (version_name, from schemas.py)
    callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        # monitor: train_loss   # The metric to monitor.
        # mode: min           # The direction to optimize the metric.
        # save_last: true     # Whether to save the last checkpoint.
        # save_top_k: 1       # The number of best checkpoints to save.
        filename: 'best'  # The filename to use for the checkpoint.
    # - class_path: lightning.pytorch.callbacks.EarlyStopping
    #   init_args:
    #     monitor: val_loss   # The metric to monitor.
    #     patience: 30        # The number of epochs with no improvement after which training will be stopped.
    #     mode: min           # The direction to optimize the metric.
    deterministic: warn
run:
  task: fit                 # The task to run.
  data: null                # (???) It will be overwritten dinamically (data/file_path)
  ckpt_path: null           # (???) It will be overwritten by execution dinamically (if ckpt/resume is set to True)